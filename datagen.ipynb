{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using KnetLayers, Random, Plots, DataFrames, StatsPlots, Query, PlotThemes, CSV\n",
    "import KnetLayers: IndexedDict, arrtype, nllmask\n",
    "setoptim!(M, optimizer) = for p in params(M); p.opt = deepcopy(optimizer); end\n",
    "gpu(0)\n",
    "KnetLayers.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot()\n",
    "theme(:ggplot2)\n",
    "ENV[\"COLUMNS\"] = 500\n",
    "ENV[\"LINES\"]   = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab    = IndexedDict([collect('0':'9'); collect('a':'z')])\n",
    "digits   = '0':2:'8'\n",
    "chars    = 'a':'h'\n",
    "holdout  = ['0' .* ('a':'b'); '2'.*('c':'d'); '4'.*('e':'f'); '8'.*('g':'h'); \"6h\"]\n",
    "data     = [d*c for d in digits, c in chars if d*c ∉ holdout ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝑿 = [vocab[collect(d)] for d in data]\n",
    "V = length(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact(e,h,W)     = softmax(sum(e .* (W * h), dims=1))\n",
    "interact(e,h,W)     = softmax(e .* (W * h))\n",
    "drop(x)             = dropout(x, 0.5)\n",
    "function attend(e,h,W,layer) \n",
    "    α = interact(e,h,W)\n",
    "    layer(sum(drop(α .* h), dims=2)), α \n",
    "end\n",
    "function encode(model, xi, 𝑿╲i=nothing)\n",
    "    e   = drop(vec(model.encoder(xi))) # 2H\n",
    "    if isnothing(𝑿╲i)\n",
    "        model.Wμ(e), model.Wσ(e), nothing\n",
    "    else          \n",
    "        h          = drop(mat(model.encoder(𝑿╲i))) # H x 2 x (T-1)\n",
    "        μ, αμ      = attend(e,h,model.Wμa.weight,model.Wμ)\n",
    "        logσ², ασ  = attend(e,h,model.Wσa.weight,model.Wσ)\n",
    "        μ, logσ², (αμ=αμ,ασ=ασ)\n",
    "    end \n",
    "end\n",
    "\n",
    "function decode(model, zi, 𝑿╲i=nothing)\n",
    "    if !isnothing(𝑿╲i)\n",
    "        h      = mat(drop(model.encoder(𝑿╲i)))  # H x 2 x (T-1)\n",
    "        zi, αz = attend(zi,h,model.Wza.weight,model.Wz)\n",
    "        model.decoder(reshape(zi,size(zi,1) ÷ 2,2)), αz\n",
    "    else\n",
    "        model.decoder(reshape(zi,size(zi,1) ÷ 2,2)), nothing\n",
    "    end\n",
    "end\n",
    "    \n",
    "\n",
    "isencatt(model)    = haskey(model, :Wμa) &&  haskey(model, :Wσa) \n",
    "isdecatt(model)    = haskey(model, :Wza) \n",
    "hiddensize(model)  = size(model.encoder.weight,1)\n",
    "elementtype(model) = eltype(model.encoder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(model, xi, 𝑿╲i; encatt=false, decatt=false, results=false)\n",
    "    μ, logσ², αe =  encode(model, xi, (encatt ? 𝑿╲i : nothing))\n",
    "    σ² = exp.(logσ²)\n",
    "    σ  = sqrt.(σ²)\n",
    "    z  = μ .+ randn!(similar(μ)) .* σ\n",
    "    xp, αd = decode(model, z, (decatt ? 𝑿╲i : nothing))\n",
    "    KL = -sum(1 .+ logσ² .- μ.^2 .- σ²)/ 2length(μ)\n",
    "    L  = nll(xp,xi) + KL\n",
    "    if results\n",
    "        L, greedy(xp), (αe=αe, αd=αd)\n",
    "    else\n",
    "        L\n",
    "    end\n",
    "end\n",
    "\n",
    "function eval(model, vocab, 𝑿)\n",
    "    results  = Dict()\n",
    "    for i=1:length(𝑿)\n",
    "        xi  = 𝑿[i]\n",
    "        𝑿╲i = hcat([𝑿[1:i-1]; 𝑿[i+1:end]]...)\n",
    "        L, y, att = loss(model, xi,  𝑿╲i; encatt=isencatt(model), decatt=isdecatt(model), results=true)\n",
    "        results[xi] = (L=L,y=y,att=att)\n",
    "    end\n",
    "    decres = empty(results)\n",
    "    for (k,v) in results\n",
    "        decres[join(vocab[k])] = (L=v.L,y=join(vocab[v.y]), att = v.att)\n",
    "    end\n",
    "    return decres\n",
    "end\n",
    "\n",
    "function train!(model, 𝑿; epoch=20, optim=Adam())\n",
    "    setoptim!(model,optim)\n",
    "    for i=1:epoch\n",
    "        lss, cnt= 0.,0.\n",
    "        for (i,xi) in enumerate(shuffle(𝑿))\n",
    "            xi   = 𝑿[i]\n",
    "            𝑿╲i = hcat([𝑿[1:i-1]; 𝑿[i+1:end] ]...)\n",
    "            J = @diff loss(model, xi, 𝑿╲i, encatt=isencatt(model), decatt=isdecatt(model))\n",
    "            for w in params(J)\n",
    "                KnetLayers.update!(value(w), grad(J,w), w.opt)\n",
    "            end            \n",
    "            lss += value(J)\n",
    "            cnt += 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function samplingparams(model, 𝑿; useprior=false)\n",
    "    H,T   = hiddensize(model), elementtype(model)\n",
    "    if useprior\n",
    "        arrtype(zeros(T,2H,1)), arrtype(ones(T,2H,1))\n",
    "    else\n",
    "        μ, σ² = arrtype(zeros(T,2H,1)), arrtype(zeros(T,2H,1))\n",
    "        for i=1:length(𝑿)\n",
    "            xi  = 𝑿[i]\n",
    "            𝑿╲i = hcat([𝑿[1:i-1];𝑿[i+1:end]]...)\n",
    "            μi, logσ²,_ =  encode(model, xi,  isencatt(model) ? 𝑿╲i : nothing)\n",
    "            μ  .+= μi\n",
    "            σ² .+= exp.(logσ²)\n",
    "        end\n",
    "        μ/length(𝑿),  σ²/length(𝑿)\n",
    "    end\n",
    "end\n",
    "\n",
    "function sample(model, vocab, 𝑿; N=100, useprior=false)\n",
    "    μ, σ² =  samplingparams(model,𝑿; useprior=useprior) \n",
    "    σ  = sqrt.(σ²)\n",
    "    𝑿 =  hcat(𝑿...)\n",
    "    samples = []\n",
    "    for i=1:N\n",
    "        z     = μ .+ randn!(similar(μ)) .* σ\n",
    "        xp, _ = decode(model, z, (isdecatt(model) ? 𝑿 : nothing))\n",
    "        push!(samples,join(vocab[greedy(xp)]))\n",
    "    end\n",
    "    return samples\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact(e,h,W)     = softmax(sum(e .* (W * h), dims=1))\n",
    "# interact_b(e,h,mask::Nothing) = softmax(e .* h, dims=(1,2))\n",
    "# drop(x) = dropout(x, 0.5)\n",
    "function interact(e, h; mask=nothing, sumout=false)\n",
    "    y = isnothing(mask) ?  (e .* h) : ( e .* h .+ mask)\n",
    "    if sumout\n",
    "        α = softmax(mat(sum(y,dims=1)),dims=1)\n",
    "        reshape(α,1,size(α)...)\n",
    "    else\n",
    "        softmax(y, dims=(1,2))\n",
    "    end\n",
    "end\n",
    "\n",
    "function attend(e, h, W, layer, mask=nothing; sumout=false) \n",
    "    h3d = reshape(W*h, size(h,1),size(h,2),1)\n",
    "    h   = reshape(h, size(h,1),size(h,2),1)\n",
    "    α   = interact(e,h3d; mask=mask, sumout=sumout)  \n",
    "    layer(mat(sum(drop(α .* h), dims=2))), α \n",
    "end\n",
    "\n",
    "function encode(model, xi, 𝑿=nothing, mask=nothing)\n",
    "    e = drop(model.encoder(xi))\n",
    "    H,N,B = size(e)\n",
    "    if isnothing(𝑿)\n",
    "        e = reshape(e,H*N,B)\n",
    "        model.Wμ(e), model.Wσ(e), nothing\n",
    "    else   \n",
    "        e = reshape(e,H*N,1,B)\n",
    "        h  = drop(mat(model.encoder(𝑿))) # 2H x  L\n",
    "        μ, αμ    = attend(e,h,model.Wμa.weight,model.Wμ, mask)\n",
    "        logσ², ασ = attend(e,h,model.Wσa.weight,model.Wσ, mask)\n",
    "        μ, logσ², (αμ=αμ,ασ=ασ)\n",
    "    end \n",
    "end\n",
    "\n",
    "function decode(model, zi, 𝑿=nothing, mask=nothing)\n",
    "    if !isnothing(𝑿)\n",
    "        h      = mat(drop(model.encoder(𝑿)))  # 2H x B\n",
    "        zi     = reshape(zi,size(zi,1),1,size(zi,2))\n",
    "        zi, αz = attend(zi,h,model.Wza.weight,model.Wz, mask)\n",
    "        model.decoder(reshape(zi,size(zi,1) ÷ 2,2,size(zi,2))), αz\n",
    "    else\n",
    "        model.decoder(reshape(zi,size(zi,1) ÷ 2,2,size(zi,2))), nothing\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function loss(model, xi, 𝑿; mask=nothing, encatt=false, decatt=false, results=false)\n",
    "    μ, logσ², αe =  encode(model, xi, (encatt ? 𝑿 : nothing), mask)\n",
    "    σ² = exp.(logσ²)\n",
    "    σ  = sqrt.(σ²)\n",
    "    z  = μ .+ randn!(similar(μ)) .* σ\n",
    "    xp, αd = decode(model, z, (decatt ? 𝑿 : nothing), mask)\n",
    "    KL = -sum(1.0f0 .+ logσ² .- μ.^2 .- σ²) / 2length(μ)\n",
    "    L  = nllmask(xp,xi) + KL\n",
    "    if results\n",
    "        L, greedy(xp), (αe=αe, αd=αd)\n",
    "    else\n",
    "        L\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function get_mask(indices,L)\n",
    "    B = length(indices)\n",
    "    mask = zeros(Float32,1,L,B)\n",
    "    for (i,ind) in enumerate(indices)\n",
    "        mask[1,ind,i] = -1.0f30\n",
    "    end\n",
    "    return arrtype(mask)\n",
    "end\n",
    "    \n",
    "\n",
    "batches(X,B) = [collect(i:i+B-1) for i=1:B:length(X)-B+1]\n",
    "\n",
    "    \n",
    "function train!(model, 𝑿; epoch=20, optim=Adam(), B=2)\n",
    "    setoptim!(model,optim)\n",
    "    for i=1:epoch\n",
    "        lss, cnt= 0.,0.\n",
    "        X = shuffle(𝑿)\n",
    "        for (i,indices) in enumerate(batches(X,B))\n",
    "            xi   = hcat(X[indices]...)\n",
    "            xt   = hcat(X...)\n",
    "            mask = get_mask(indices,length(X))\n",
    "            J = @diff loss(model, xi, xt, mask=mask, encatt=isencatt(model), decatt=isdecatt(model))\n",
    "            for w in params(J)\n",
    "                KnetLayers.update!(value(w), grad(J,w), w.opt)\n",
    "            end            \n",
    "            lss += value(J)\n",
    "            cnt += 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function samplingparams(model, 𝑿; useprior=false, B=2)\n",
    "    H,T   = hiddensize(model), elementtype(model)\n",
    "    if useprior\n",
    "        arrtype(zeros(T,2H,1)), arrtype(ones(T,2H,1))\n",
    "    else\n",
    "        μ, σ² = arrtype(zeros(T,2H,1)), arrtype(zeros(T,2H,1))\n",
    "        for (i,indices) in enumerate(batches(𝑿,B))\n",
    "            xi   = hcat(𝑿[indices]...)\n",
    "            xt   = hcat(𝑿...)\n",
    "            mask = get_mask(indices,length(𝑿))\n",
    "            μi, logσ²,_ =  encode(model, xi,  isencatt(model) ? xt : nothing, mask)\n",
    "            μ  .+= sum(μi,dims=2)\n",
    "            σ² .+= sum(exp.(logσ²),dims=2)\n",
    "        end\n",
    "        μ/length(𝑿),  σ²/length(𝑿)\n",
    "    end\n",
    "end\n",
    "\n",
    "greedy(y) = mapslices(argmax, y, dims=1)\n",
    "function sample(model, vocab, 𝑿; N=100, useprior=false)\n",
    "    μ, σ² =  samplingparams(model,𝑿; useprior=useprior) \n",
    "    xt    =  hcat(𝑿...)\n",
    "    r     =  similar(μ,size(μ,1),N)\n",
    "    z     =  μ .+ randn!(r) .* sqrt.(σ²)\n",
    "    xp, _ =  decode(model, z, (isdecatt(model) ? xt : nothing),  nothing)\n",
    "    vec(mapslices(x->join(vocab[greedy(x)]), convert(Array, xp), dims=(1,2)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel = get_vae_models(256)[3]\n",
    "train!(cmodel, 𝑿; epoch=30, optim=Adam(),B=2)\n",
    "sampled = sample(cmodel, vocab, 𝑿; N=100)\n",
    "unseen = [s for s in sampled if s ∈ holdout]\n",
    "wrong  = [s for s in sampled if s ∉ [data;holdout]]   \n",
    "unique(unseen)\n",
    "# push!(df2, (isencatt(cmodel), isdecatt(cmodel), H, opt.lr, \"$opt\", epoch,  length(unseen), length(holdout)-length(unique(unseen)), length(wrong),length(unique(unseen)) ))\n",
    "# print((row+=1), \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function probmap(y)\n",
    "    u=unique(y)\n",
    "    Dict([(i,count(x->x==i,y) / length(y)) for i in u])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_vae_models(H=256)\n",
    "    encoder    = Embed(input=V,output=H)\n",
    "    decoder    = Embed(input=H,output=V)\n",
    "    Wμa        = Multiply(input=2H,output=2H)\n",
    "    Wμ         = Dense(input=2H,output=2H, activation=ELU())\n",
    "    Wza        = Multiply(input=2H,output=2H)\n",
    "    Wz         = Dense(input=2H,output=2H, activation=ELU())\n",
    "    Wσa        = Multiply(input=2H,output=2H)\n",
    "    Wσ         = Dense(input=2H,output=2H, activation=ELU())\n",
    "    model_atte = (encoder=encoder, Wμa=Wμa, Wμ=Wμ, Wσa=Wσa, Wσ=Wσ, decoder=decoder)\n",
    "    model_vae  = (encoder=encoder, Wμa=Wμa, Wμ=Wμ, Wσ=Wσ, decoder=decoder)\n",
    "    model_attd = (encoder=encoder, Wμ=Wμ, Wσ=Wσ, Wza=Wza, Wz=Wz, decoder=decoder)\n",
    "    model_attde = (encoder=encoder, Wμa=Wμa, Wμ=Wμ, Wσa=Wσa, Wσ=Wσ, Wza=Wza, Wz=Wz, decoder=decoder)\n",
    "    (model_vae, model_atte, model_attd, model_attde);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>EncoderAtt</th><th>DecoderAtt</th><th>B</th><th>H</th><th>lr</th><th>Optimizer</th><th>Epoch</th><th>UnseenCnt</th><th>MissedClass</th><th>WrongCount</th></tr><tr><th></th><th>Bool</th><th>Bool</th><th>Int64</th><th>Int64</th><th>Float64</th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>0 rows × 10 columns</p></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& EncoderAtt & DecoderAtt & B & H & lr & Optimizer & Epoch & UnseenCnt & MissedClass & WrongCount\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Bool & Int64 & Int64 & Float64 & String & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "0×10 DataFrame\n"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = DataFrame(EncoderAtt = Bool[], DecoderAtt = Bool[], B=Int[], H = Int[], lr=Float64[], Optimizer = String[], Epoch = Int[], UnseenCnt=Int[], MissedClass=Int[], WrongCount=Int[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 "
     ]
    }
   ],
   "source": [
    "row = 0\n",
    "for H in (256,128)\n",
    "    for opt in (Adam, Rmsprop, SGD)\n",
    "        for lr in (0.001, 0.01, 0.1, 1.0)\n",
    "            for B in (1,2,4,8,16)\n",
    "                for epoch in (10,20,30)\n",
    "                    for model in get_vae_models(H)\n",
    "                        cmodel = deepcopy(model)\n",
    "                        train!(cmodel, 𝑿; epoch=epoch, optim=opt(lr=lr))\n",
    "                        sampled = sample(cmodel, vocab, 𝑿; N=100)\n",
    "                        unseen = [s for s in sampled if s ∈ holdout]\n",
    "                        wrong  = [s for s in sampled if s ∉ [data;holdout]]              \n",
    "                        push!(df2, (isencatt(cmodel), isdecatt(cmodel), B, H, lr, \"$opt\", epoch,  length(unseen), length(holdout)-length(unique(unseen)), length(wrong)))\n",
    "                        print((row+=1), \" \")\n",
    "                    end\n",
    "                end\n",
    "           end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "df2[!,:UnseenClass] = length(holdout) .- df2.MissedClass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[!,:UnseenClass] = length(holdout) .- df2.MissedClass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>EncoderAtt</th><th>DecoderAtt</th><th>B</th><th>H</th><th>lr</th><th>Optimizer</th><th>Epoch</th><th>UnseenCnt</th><th>MissedClass</th><th>WrongCount</th><th>UnseenClass</th></tr><tr><th></th><th>Bool</th><th>Bool</th><th>Int64</th><th>Int64</th><th>Float64</th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>1,440 rows × 11 columns</p><tr><th>1</th><td>0</td><td>0</td><td>4</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>23</td><td>0</td><td>0</td><td>9</td></tr><tr><th>2</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>20</td><td>21</td><td>0</td><td>0</td><td>9</td></tr><tr><th>3</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>27</td><td>0</td><td>0</td><td>9</td></tr><tr><th>4</th><td>1</td><td>0</td><td>2</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>20</td><td>0</td><td>0</td><td>9</td></tr><tr><th>5</th><td>1</td><td>0</td><td>16</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>26</td><td>0</td><td>0</td><td>9</td></tr><tr><th>6</th><td>1</td><td>0</td><td>2</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>18</td><td>0</td><td>0</td><td>9</td></tr><tr><th>7</th><td>0</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Adam</td><td>10</td><td>23</td><td>0</td><td>1</td><td>9</td></tr><tr><th>8</th><td>1</td><td>0</td><td>2</td><td>256</td><td>0.01</td><td>Adam</td><td>30</td><td>20</td><td>0</td><td>1</td><td>9</td></tr><tr><th>9</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.01</td><td>Adam</td><td>20</td><td>23</td><td>0</td><td>1</td><td>9</td></tr><tr><th>10</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>20</td><td>26</td><td>0</td><td>1</td><td>9</td></tr><tr><th>11</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>20</td><td>20</td><td>0</td><td>1</td><td>9</td></tr><tr><th>12</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>18</td><td>0</td><td>1</td><td>9</td></tr><tr><th>13</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.01</td><td>Adam</td><td>20</td><td>21</td><td>0</td><td>1</td><td>9</td></tr><tr><th>14</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>17</td><td>0</td><td>2</td><td>9</td></tr><tr><th>15</th><td>1</td><td>0</td><td>2</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>25</td><td>0</td><td>2</td><td>9</td></tr><tr><th>16</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>24</td><td>0</td><td>2</td><td>9</td></tr><tr><th>17</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>17</td><td>0</td><td>2</td><td>9</td></tr><tr><th>18</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>26</td><td>0</td><td>2</td><td>9</td></tr><tr><th>19</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>20</td><td>23</td><td>0</td><td>2</td><td>9</td></tr><tr><th>20</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>15</td><td>0</td><td>2</td><td>9</td></tr><tr><th>21</th><td>1</td><td>0</td><td>2</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>24</td><td>0</td><td>3</td><td>9</td></tr><tr><th>22</th><td>1</td><td>0</td><td>4</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>22</td><td>0</td><td>3</td><td>9</td></tr><tr><th>23</th><td>0</td><td>0</td><td>1</td><td>256</td><td>0.001</td><td>Adam</td><td>20</td><td>23</td><td>0</td><td>4</td><td>9</td></tr><tr><th>24</th><td>0</td><td>0</td><td>2</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>22</td><td>0</td><td>4</td><td>9</td></tr><tr><th>25</th><td>0</td><td>0</td><td>2</td><td>128</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>22</td><td>0</td><td>4</td><td>9</td></tr><tr><th>26</th><td>0</td><td>0</td><td>4</td><td>128</td><td>0.001</td><td>Adam</td><td>30</td><td>19</td><td>0</td><td>5</td><td>9</td></tr><tr><th>27</th><td>1</td><td>0</td><td>2</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>23</td><td>0</td><td>6</td><td>9</td></tr><tr><th>28</th><td>0</td><td>0</td><td>16</td><td>128</td><td>0.001</td><td>Adam</td><td>30</td><td>19</td><td>0</td><td>6</td><td>9</td></tr><tr><th>29</th><td>0</td><td>0</td><td>2</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>24</td><td>0</td><td>8</td><td>9</td></tr><tr><th>30</th><td>0</td><td>0</td><td>2</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>23</td><td>0</td><td>9</td><td>9</td></tr><tr><th>31</th><td>1</td><td>0</td><td>16</td><td>128</td><td>0.1</td><td>SGD</td><td>10</td><td>19</td><td>0</td><td>9</td><td>9</td></tr><tr><th>32</th><td>0</td><td>0</td><td>4</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>20</td><td>0</td><td>13</td><td>9</td></tr><tr><th>33</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.1</td><td>SGD</td><td>10</td><td>23</td><td>0</td><td>14</td><td>9</td></tr><tr><th>34</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.1</td><td>SGD</td><td>10</td><td>22</td><td>0</td><td>14</td><td>9</td></tr><tr><th>35</th><td>0</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>17</td><td>0</td><td>17</td><td>9</td></tr><tr><th>36</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>21</td><td>0</td><td>27</td><td>9</td></tr><tr><th>37</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.01</td><td>Adam</td><td>10</td><td>23</td><td>1</td><td>0</td><td>8</td></tr><tr><th>38</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.01</td><td>Adam</td><td>30</td><td>22</td><td>1</td><td>0</td><td>8</td></tr><tr><th>39</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.01</td><td>Adam</td><td>20</td><td>21</td><td>1</td><td>0</td><td>8</td></tr><tr><th>40</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.01</td><td>Adam</td><td>30</td><td>20</td><td>1</td><td>0</td><td>8</td></tr><tr><th>41</th><td>1</td><td>0</td><td>1</td><td>128</td><td>0.01</td><td>Adam</td><td>20</td><td>18</td><td>1</td><td>0</td><td>8</td></tr><tr><th>42</th><td>1</td><td>0</td><td>2</td><td>128</td><td>0.01</td><td>Adam</td><td>20</td><td>17</td><td>1</td><td>0</td><td>8</td></tr><tr><th>43</th><td>1</td><td>0</td><td>4</td><td>128</td><td>0.01</td><td>Adam</td><td>20</td><td>20</td><td>1</td><td>0</td><td>8</td></tr><tr><th>44</th><td>1</td><td>0</td><td>4</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>21</td><td>1</td><td>0</td><td>8</td></tr><tr><th>45</th><td>1</td><td>0</td><td>2</td><td>128</td><td>0.1</td><td>SGD</td><td>30</td><td>21</td><td>1</td><td>0</td><td>8</td></tr><tr><th>46</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>24</td><td>1</td><td>1</td><td>8</td></tr><tr><th>47</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>20</td><td>1</td><td>1</td><td>8</td></tr><tr><th>48</th><td>0</td><td>0</td><td>8</td><td>128</td><td>0.001</td><td>Adam</td><td>20</td><td>22</td><td>1</td><td>1</td><td>8</td></tr><tr><th>49</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.01</td><td>Adam</td><td>10</td><td>23</td><td>1</td><td>1</td><td>8</td></tr><tr><th>50</th><td>1</td><td>0</td><td>16</td><td>128</td><td>0.01</td><td>Adam</td><td>10</td><td>17</td><td>1</td><td>1</td><td>8</td></tr><tr><th>51</th><td>1</td><td>0</td><td>16</td><td>128</td><td>0.01</td><td>Adam</td><td>30</td><td>20</td><td>1</td><td>1</td><td>8</td></tr><tr><th>52</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>26</td><td>1</td><td>1</td><td>8</td></tr><tr><th>53</th><td>1</td><td>0</td><td>1</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>19</td><td>1</td><td>1</td><td>8</td></tr><tr><th>54</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>55</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.01</td><td>Adam</td><td>20</td><td>26</td><td>1</td><td>2</td><td>8</td></tr><tr><th>56</th><td>0</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>18</td><td>1</td><td>2</td><td>8</td></tr><tr><th>57</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>58</th><td>0</td><td>0</td><td>1</td><td>128</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>59</th><td>1</td><td>0</td><td>1</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>60</th><td>1</td><td>0</td><td>16</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>61</th><td>1</td><td>0</td><td>4</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>20</td><td>1</td><td>2</td><td>8</td></tr><tr><th>62</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.1</td><td>SGD</td><td>30</td><td>21</td><td>1</td><td>2</td><td>8</td></tr><tr><th>63</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>20</td><td>1</td><td>3</td><td>8</td></tr><tr><th>64</th><td>0</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>10</td><td>26</td><td>1</td><td>3</td><td>8</td></tr><tr><th>65</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>22</td><td>1</td><td>3</td><td>8</td></tr><tr><th>66</th><td>1</td><td>0</td><td>1</td><td>128</td><td>0.1</td><td>Adam</td><td>30</td><td>11</td><td>1</td><td>3</td><td>8</td></tr><tr><th>67</th><td>1</td><td>0</td><td>1</td><td>128</td><td>0.1</td><td>SGD</td><td>30</td><td>17</td><td>1</td><td>3</td><td>8</td></tr><tr><th>68</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>19</td><td>1</td><td>4</td><td>8</td></tr><tr><th>69</th><td>1</td><td>0</td><td>2</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>23</td><td>1</td><td>4</td><td>8</td></tr><tr><th>70</th><td>0</td><td>0</td><td>4</td><td>256</td><td>0.001</td><td>Adam</td><td>20</td><td>17</td><td>1</td><td>4</td><td>8</td></tr><tr><th>71</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>20</td><td>1</td><td>4</td><td>8</td></tr><tr><th>72</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>20</td><td>28</td><td>1</td><td>4</td><td>8</td></tr><tr><th>73</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.01</td><td>Rmsprop</td><td>10</td><td>28</td><td>1</td><td>4</td><td>8</td></tr><tr><th>74</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.01</td><td>Rmsprop</td><td>30</td><td>26</td><td>1</td><td>5</td><td>8</td></tr><tr><th>75</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>22</td><td>1</td><td>5</td><td>8</td></tr><tr><th>76</th><td>0</td><td>0</td><td>2</td><td>128</td><td>0.001</td><td>Adam</td><td>30</td><td>19</td><td>1</td><td>5</td><td>8</td></tr><tr><th>77</th><td>0</td><td>0</td><td>4</td><td>128</td><td>0.001</td><td>Rmsprop</td><td>20</td><td>18</td><td>1</td><td>5</td><td>8</td></tr><tr><th>78</th><td>0</td><td>0</td><td>16</td><td>128</td><td>0.1</td><td>SGD</td><td>30</td><td>22</td><td>1</td><td>5</td><td>8</td></tr><tr><th>79</th><td>0</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Adam</td><td>30</td><td>12</td><td>1</td><td>6</td><td>8</td></tr><tr><th>80</th><td>1</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>18</td><td>1</td><td>6</td><td>8</td></tr><tr><th>81</th><td>0</td><td>0</td><td>4</td><td>128</td><td>0.1</td><td>SGD</td><td>20</td><td>28</td><td>1</td><td>6</td><td>8</td></tr><tr><th>82</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>12</td><td>1</td><td>7</td><td>8</td></tr><tr><th>83</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.1</td><td>SGD</td><td>10</td><td>24</td><td>1</td><td>7</td><td>8</td></tr><tr><th>84</th><td>0</td><td>0</td><td>16</td><td>256</td><td>0.1</td><td>SGD</td><td>10</td><td>20</td><td>1</td><td>7</td><td>8</td></tr><tr><th>85</th><td>1</td><td>0</td><td>4</td><td>128</td><td>0.001</td><td>Adam</td><td>30</td><td>25</td><td>1</td><td>7</td><td>8</td></tr><tr><th>86</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Adam</td><td>20</td><td>19</td><td>1</td><td>8</td><td>8</td></tr><tr><th>87</th><td>0</td><td>0</td><td>8</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>18</td><td>1</td><td>8</td><td>8</td></tr><tr><th>88</th><td>1</td><td>0</td><td>8</td><td>128</td><td>0.1</td><td>SGD</td><td>10</td><td>23</td><td>1</td><td>8</td><td>8</td></tr><tr><th>89</th><td>1</td><td>0</td><td>16</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>19</td><td>1</td><td>9</td><td>8</td></tr><tr><th>90</th><td>0</td><td>0</td><td>4</td><td>128</td><td>0.001</td><td>Adam</td><td>10</td><td>15</td><td>1</td><td>9</td><td>8</td></tr><tr><th>91</th><td>0</td><td>0</td><td>1</td><td>256</td><td>0.1</td><td>SGD</td><td>20</td><td>23</td><td>1</td><td>10</td><td>8</td></tr><tr><th>92</th><td>1</td><td>0</td><td>2</td><td>128</td><td>0.001</td><td>Adam</td><td>30</td><td>14</td><td>1</td><td>10</td><td>8</td></tr><tr><th>93</th><td>0</td><td>0</td><td>1</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>22</td><td>1</td><td>11</td><td>8</td></tr><tr><th>94</th><td>0</td><td>0</td><td>4</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>15</td><td>1</td><td>11</td><td>8</td></tr><tr><th>95</th><td>0</td><td>0</td><td>4</td><td>128</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>25</td><td>1</td><td>12</td><td>8</td></tr><tr><th>96</th><td>0</td><td>0</td><td>1</td><td>128</td><td>0.1</td><td>SGD</td><td>10</td><td>18</td><td>1</td><td>12</td><td>8</td></tr><tr><th>97</th><td>1</td><td>0</td><td>4</td><td>256</td><td>0.001</td><td>Adam</td><td>20</td><td>13</td><td>1</td><td>13</td><td>8</td></tr><tr><th>98</th><td>0</td><td>0</td><td>8</td><td>256</td><td>0.001</td><td>Rmsprop</td><td>30</td><td>18</td><td>1</td><td>13</td><td>8</td></tr><tr><th>99</th><td>0</td><td>0</td><td>16</td><td>256</td><td>0.1</td><td>SGD</td><td>30</td><td>17</td><td>1</td><td>13</td><td>8</td></tr><tr><th>100</th><td>1</td><td>0</td><td>1</td><td>256</td><td>0.001</td><td>Adam</td><td>20</td><td>14</td><td>1</td><td>14</td><td>8</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& EncoderAtt & DecoderAtt & B & H & lr & Optimizer & Epoch & UnseenCnt & MissedClass & WrongCount & UnseenClass\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Bool & Int64 & Int64 & Float64 & String & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 0 & 4 & 256 & 0.001 & Rmsprop & 20 & 23 & 0 & 0 & 9 \\\\\n",
       "\t2 & 1 & 0 & 1 & 256 & 0.01 & Rmsprop & 20 & 21 & 0 & 0 & 9 \\\\\n",
       "\t3 & 1 & 0 & 4 & 256 & 0.01 & Rmsprop & 10 & 27 & 0 & 0 & 9 \\\\\n",
       "\t4 & 1 & 0 & 2 & 128 & 0.01 & Rmsprop & 10 & 20 & 0 & 0 & 9 \\\\\n",
       "\t5 & 1 & 0 & 16 & 128 & 0.01 & Rmsprop & 30 & 26 & 0 & 0 & 9 \\\\\n",
       "\t6 & 1 & 0 & 2 & 128 & 0.1 & SGD & 20 & 18 & 0 & 0 & 9 \\\\\n",
       "\t7 & 0 & 0 & 8 & 256 & 0.001 & Adam & 10 & 23 & 0 & 1 & 9 \\\\\n",
       "\t8 & 1 & 0 & 2 & 256 & 0.01 & Adam & 30 & 20 & 0 & 1 & 9 \\\\\n",
       "\t9 & 1 & 0 & 4 & 256 & 0.01 & Adam & 20 & 23 & 0 & 1 & 9 \\\\\n",
       "\t10 & 1 & 0 & 4 & 256 & 0.01 & Rmsprop & 20 & 26 & 0 & 1 & 9 \\\\\n",
       "\t11 & 1 & 0 & 8 & 256 & 0.01 & Rmsprop & 20 & 20 & 0 & 1 & 9 \\\\\n",
       "\t12 & 1 & 0 & 16 & 256 & 0.01 & Rmsprop & 10 & 18 & 0 & 1 & 9 \\\\\n",
       "\t13 & 1 & 0 & 8 & 128 & 0.01 & Adam & 20 & 21 & 0 & 1 & 9 \\\\\n",
       "\t14 & 1 & 0 & 1 & 256 & 0.01 & Rmsprop & 10 & 17 & 0 & 2 & 9 \\\\\n",
       "\t15 & 1 & 0 & 2 & 256 & 0.1 & SGD & 20 & 25 & 0 & 2 & 9 \\\\\n",
       "\t16 & 1 & 0 & 4 & 256 & 0.1 & SGD & 30 & 24 & 0 & 2 & 9 \\\\\n",
       "\t17 & 1 & 0 & 16 & 256 & 0.1 & SGD & 20 & 17 & 0 & 2 & 9 \\\\\n",
       "\t18 & 1 & 0 & 16 & 256 & 0.1 & SGD & 30 & 26 & 0 & 2 & 9 \\\\\n",
       "\t19 & 1 & 0 & 8 & 128 & 0.01 & Rmsprop & 20 & 23 & 0 & 2 & 9 \\\\\n",
       "\t20 & 1 & 0 & 8 & 128 & 0.1 & SGD & 20 & 15 & 0 & 2 & 9 \\\\\n",
       "\t21 & 1 & 0 & 2 & 256 & 0.1 & SGD & 30 & 24 & 0 & 3 & 9 \\\\\n",
       "\t22 & 1 & 0 & 4 & 128 & 0.01 & Rmsprop & 10 & 22 & 0 & 3 & 9 \\\\\n",
       "\t23 & 0 & 0 & 1 & 256 & 0.001 & Adam & 20 & 23 & 0 & 4 & 9 \\\\\n",
       "\t24 & 0 & 0 & 2 & 256 & 0.001 & Rmsprop & 20 & 22 & 0 & 4 & 9 \\\\\n",
       "\t25 & 0 & 0 & 2 & 128 & 0.001 & Rmsprop & 30 & 22 & 0 & 4 & 9 \\\\\n",
       "\t26 & 0 & 0 & 4 & 128 & 0.001 & Adam & 30 & 19 & 0 & 5 & 9 \\\\\n",
       "\t27 & 1 & 0 & 2 & 256 & 0.001 & Rmsprop & 30 & 23 & 0 & 6 & 9 \\\\\n",
       "\t28 & 0 & 0 & 16 & 128 & 0.001 & Adam & 30 & 19 & 0 & 6 & 9 \\\\\n",
       "\t29 & 0 & 0 & 2 & 128 & 0.1 & SGD & 20 & 24 & 0 & 8 & 9 \\\\\n",
       "\t30 & 0 & 0 & 2 & 256 & 0.1 & SGD & 30 & 23 & 0 & 9 & 9 \\\\\n",
       "\t31 & 1 & 0 & 16 & 128 & 0.1 & SGD & 10 & 19 & 0 & 9 & 9 \\\\\n",
       "\t32 & 0 & 0 & 4 & 256 & 0.1 & SGD & 20 & 20 & 0 & 13 & 9 \\\\\n",
       "\t33 & 1 & 0 & 4 & 256 & 0.1 & SGD & 10 & 23 & 0 & 14 & 9 \\\\\n",
       "\t34 & 1 & 0 & 16 & 256 & 0.1 & SGD & 10 & 22 & 0 & 14 & 9 \\\\\n",
       "\t35 & 0 & 0 & 16 & 256 & 0.001 & Rmsprop & 30 & 17 & 0 & 17 & 9 \\\\\n",
       "\t36 & 1 & 0 & 8 & 256 & 0.001 & Rmsprop & 20 & 21 & 0 & 27 & 9 \\\\\n",
       "\t37 & 1 & 0 & 1 & 256 & 0.01 & Adam & 10 & 23 & 1 & 0 & 8 \\\\\n",
       "\t38 & 1 & 0 & 4 & 256 & 0.01 & Adam & 30 & 22 & 1 & 0 & 8 \\\\\n",
       "\t39 & 1 & 0 & 16 & 256 & 0.01 & Adam & 20 & 21 & 1 & 0 & 8 \\\\\n",
       "\t40 & 1 & 0 & 16 & 256 & 0.01 & Adam & 30 & 20 & 1 & 0 & 8 \\\\\n",
       "\t41 & 1 & 0 & 1 & 128 & 0.01 & Adam & 20 & 18 & 1 & 0 & 8 \\\\\n",
       "\t42 & 1 & 0 & 2 & 128 & 0.01 & Adam & 20 & 17 & 1 & 0 & 8 \\\\\n",
       "\t43 & 1 & 0 & 4 & 128 & 0.01 & Adam & 20 & 20 & 1 & 0 & 8 \\\\\n",
       "\t44 & 1 & 0 & 4 & 128 & 0.01 & Rmsprop & 30 & 21 & 1 & 0 & 8 \\\\\n",
       "\t45 & 1 & 0 & 2 & 128 & 0.1 & SGD & 30 & 21 & 1 & 0 & 8 \\\\\n",
       "\t46 & 1 & 0 & 1 & 256 & 0.01 & Rmsprop & 30 & 24 & 1 & 1 & 8 \\\\\n",
       "\t47 & 1 & 0 & 16 & 256 & 0.01 & Rmsprop & 30 & 20 & 1 & 1 & 8 \\\\\n",
       "\t48 & 0 & 0 & 8 & 128 & 0.001 & Adam & 20 & 22 & 1 & 1 & 8 \\\\\n",
       "\t49 & 1 & 0 & 8 & 128 & 0.01 & Adam & 10 & 23 & 1 & 1 & 8 \\\\\n",
       "\t50 & 1 & 0 & 16 & 128 & 0.01 & Adam & 10 & 17 & 1 & 1 & 8 \\\\\n",
       "\t51 & 1 & 0 & 16 & 128 & 0.01 & Adam & 30 & 20 & 1 & 1 & 8 \\\\\n",
       "\t52 & 1 & 0 & 8 & 128 & 0.01 & Rmsprop & 30 & 26 & 1 & 1 & 8 \\\\\n",
       "\t53 & 1 & 0 & 1 & 128 & 0.1 & SGD & 20 & 19 & 1 & 1 & 8 \\\\\n",
       "\t54 & 1 & 0 & 16 & 256 & 0.001 & Adam & 30 & 21 & 1 & 2 & 8 \\\\\n",
       "\t55 & 1 & 0 & 8 & 256 & 0.01 & Adam & 20 & 26 & 1 & 2 & 8 \\\\\n",
       "\t56 & 0 & 0 & 8 & 256 & 0.001 & Rmsprop & 20 & 18 & 1 & 2 & 8 \\\\\n",
       "\t57 & 1 & 0 & 8 & 256 & 0.1 & SGD & 30 & 21 & 1 & 2 & 8 \\\\\n",
       "\t58 & 0 & 0 & 1 & 128 & 0.001 & Rmsprop & 20 & 21 & 1 & 2 & 8 \\\\\n",
       "\t59 & 1 & 0 & 1 & 128 & 0.01 & Rmsprop & 30 & 21 & 1 & 2 & 8 \\\\\n",
       "\t60 & 1 & 0 & 16 & 128 & 0.01 & Rmsprop & 10 & 21 & 1 & 2 & 8 \\\\\n",
       "\t61 & 1 & 0 & 4 & 128 & 0.1 & SGD & 20 & 20 & 1 & 2 & 8 \\\\\n",
       "\t62 & 1 & 0 & 8 & 128 & 0.1 & SGD & 30 & 21 & 1 & 2 & 8 \\\\\n",
       "\t63 & 1 & 0 & 4 & 256 & 0.001 & Adam & 30 & 20 & 1 & 3 & 8 \\\\\n",
       "\t64 & 0 & 0 & 16 & 256 & 0.001 & Rmsprop & 10 & 26 & 1 & 3 & 8 \\\\\n",
       "\t65 & 1 & 0 & 8 & 256 & 0.1 & SGD & 20 & 22 & 1 & 3 & 8 \\\\\n",
       "\t66 & 1 & 0 & 1 & 128 & 0.1 & Adam & 30 & 11 & 1 & 3 & 8 \\\\\n",
       "\t67 & 1 & 0 & 1 & 128 & 0.1 & SGD & 30 & 17 & 1 & 3 & 8 \\\\\n",
       "\t68 & 1 & 0 & 1 & 256 & 0.001 & Adam & 30 & 19 & 1 & 4 & 8 \\\\\n",
       "\t69 & 1 & 0 & 2 & 256 & 0.001 & Adam & 30 & 23 & 1 & 4 & 8 \\\\\n",
       "\t70 & 0 & 0 & 4 & 256 & 0.001 & Adam & 20 & 17 & 1 & 4 & 8 \\\\\n",
       "\t71 & 1 & 0 & 8 & 256 & 0.001 & Adam & 30 & 20 & 1 & 4 & 8 \\\\\n",
       "\t72 & 1 & 0 & 16 & 256 & 0.01 & Rmsprop & 20 & 28 & 1 & 4 & 8 \\\\\n",
       "\t73 & 1 & 0 & 8 & 128 & 0.01 & Rmsprop & 10 & 28 & 1 & 4 & 8 \\\\\n",
       "\t74 & 1 & 0 & 8 & 256 & 0.01 & Rmsprop & 30 & 26 & 1 & 5 & 8 \\\\\n",
       "\t75 & 1 & 0 & 4 & 256 & 0.1 & SGD & 20 & 22 & 1 & 5 & 8 \\\\\n",
       "\t76 & 0 & 0 & 2 & 128 & 0.001 & Adam & 30 & 19 & 1 & 5 & 8 \\\\\n",
       "\t77 & 0 & 0 & 4 & 128 & 0.001 & Rmsprop & 20 & 18 & 1 & 5 & 8 \\\\\n",
       "\t78 & 0 & 0 & 16 & 128 & 0.1 & SGD & 30 & 22 & 1 & 5 & 8 \\\\\n",
       "\t79 & 0 & 0 & 16 & 256 & 0.001 & Adam & 30 & 12 & 1 & 6 & 8 \\\\\n",
       "\t80 & 1 & 0 & 8 & 256 & 0.001 & Rmsprop & 30 & 18 & 1 & 6 & 8 \\\\\n",
       "\t81 & 0 & 0 & 4 & 128 & 0.1 & SGD & 20 & 28 & 1 & 6 & 8 \\\\\n",
       "\t82 & 1 & 0 & 4 & 256 & 0.001 & Rmsprop & 30 & 12 & 1 & 7 & 8 \\\\\n",
       "\t83 & 1 & 0 & 1 & 256 & 0.1 & SGD & 10 & 24 & 1 & 7 & 8 \\\\\n",
       "\t84 & 0 & 0 & 16 & 256 & 0.1 & SGD & 10 & 20 & 1 & 7 & 8 \\\\\n",
       "\t85 & 1 & 0 & 4 & 128 & 0.001 & Adam & 30 & 25 & 1 & 7 & 8 \\\\\n",
       "\t86 & 1 & 0 & 16 & 256 & 0.001 & Adam & 20 & 19 & 1 & 8 & 8 \\\\\n",
       "\t87 & 0 & 0 & 8 & 256 & 0.1 & SGD & 20 & 18 & 1 & 8 & 8 \\\\\n",
       "\t88 & 1 & 0 & 8 & 128 & 0.1 & SGD & 10 & 23 & 1 & 8 & 8 \\\\\n",
       "\t89 & 1 & 0 & 16 & 256 & 0.001 & Rmsprop & 30 & 19 & 1 & 9 & 8 \\\\\n",
       "\t90 & 0 & 0 & 4 & 128 & 0.001 & Adam & 10 & 15 & 1 & 9 & 8 \\\\\n",
       "\t91 & 0 & 0 & 1 & 256 & 0.1 & SGD & 20 & 23 & 1 & 10 & 8 \\\\\n",
       "\t92 & 1 & 0 & 2 & 128 & 0.001 & Adam & 30 & 14 & 1 & 10 & 8 \\\\\n",
       "\t93 & 0 & 0 & 1 & 256 & 0.1 & SGD & 30 & 22 & 1 & 11 & 8 \\\\\n",
       "\t94 & 0 & 0 & 4 & 256 & 0.1 & SGD & 30 & 15 & 1 & 11 & 8 \\\\\n",
       "\t95 & 0 & 0 & 4 & 128 & 0.001 & Rmsprop & 30 & 25 & 1 & 12 & 8 \\\\\n",
       "\t96 & 0 & 0 & 1 & 128 & 0.1 & SGD & 10 & 18 & 1 & 12 & 8 \\\\\n",
       "\t97 & 1 & 0 & 4 & 256 & 0.001 & Adam & 20 & 13 & 1 & 13 & 8 \\\\\n",
       "\t98 & 0 & 0 & 8 & 256 & 0.001 & Rmsprop & 30 & 18 & 1 & 13 & 8 \\\\\n",
       "\t99 & 0 & 0 & 16 & 256 & 0.1 & SGD & 30 & 17 & 1 & 13 & 8 \\\\\n",
       "\t100 & 1 & 0 & 1 & 256 & 0.001 & Adam & 20 & 14 & 1 & 14 & 8 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1440×11 DataFrame\n",
       "│ Row  │ EncoderAtt │ DecoderAtt │ B     │ H     │ lr      │ Optimizer │ Epoch │ UnseenCnt │ MissedClass │ WrongCount │ UnseenClass │\n",
       "│      │ \u001b[90mBool\u001b[39m       │ \u001b[90mBool\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mString\u001b[39m    │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m     │ \u001b[90mInt64\u001b[39m       │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m       │\n",
       "├──────┼────────────┼────────────┼───────┼───────┼─────────┼───────────┼───────┼───────────┼─────────────┼────────────┼─────────────┤\n",
       "│ 1    │ 0          │ 0          │ 4     │ 256   │ 0.001   │ Rmsprop   │ 20    │ 23        │ 0           │ 0          │ 9           │\n",
       "│ 2    │ 1          │ 0          │ 1     │ 256   │ 0.01    │ Rmsprop   │ 20    │ 21        │ 0           │ 0          │ 9           │\n",
       "│ 3    │ 1          │ 0          │ 4     │ 256   │ 0.01    │ Rmsprop   │ 10    │ 27        │ 0           │ 0          │ 9           │\n",
       "│ 4    │ 1          │ 0          │ 2     │ 128   │ 0.01    │ Rmsprop   │ 10    │ 20        │ 0           │ 0          │ 9           │\n",
       "│ 5    │ 1          │ 0          │ 16    │ 128   │ 0.01    │ Rmsprop   │ 30    │ 26        │ 0           │ 0          │ 9           │\n",
       "│ 6    │ 1          │ 0          │ 2     │ 128   │ 0.1     │ SGD       │ 20    │ 18        │ 0           │ 0          │ 9           │\n",
       "│ 7    │ 0          │ 0          │ 8     │ 256   │ 0.001   │ Adam      │ 10    │ 23        │ 0           │ 1          │ 9           │\n",
       "│ 8    │ 1          │ 0          │ 2     │ 256   │ 0.01    │ Adam      │ 30    │ 20        │ 0           │ 1          │ 9           │\n",
       "│ 9    │ 1          │ 0          │ 4     │ 256   │ 0.01    │ Adam      │ 20    │ 23        │ 0           │ 1          │ 9           │\n",
       "│ 10   │ 1          │ 0          │ 4     │ 256   │ 0.01    │ Rmsprop   │ 20    │ 26        │ 0           │ 1          │ 9           │\n",
       "│ 11   │ 1          │ 0          │ 8     │ 256   │ 0.01    │ Rmsprop   │ 20    │ 20        │ 0           │ 1          │ 9           │\n",
       "│ 12   │ 1          │ 0          │ 16    │ 256   │ 0.01    │ Rmsprop   │ 10    │ 18        │ 0           │ 1          │ 9           │\n",
       "│ 13   │ 1          │ 0          │ 8     │ 128   │ 0.01    │ Adam      │ 20    │ 21        │ 0           │ 1          │ 9           │\n",
       "│ 14   │ 1          │ 0          │ 1     │ 256   │ 0.01    │ Rmsprop   │ 10    │ 17        │ 0           │ 2          │ 9           │\n",
       "│ 15   │ 1          │ 0          │ 2     │ 256   │ 0.1     │ SGD       │ 20    │ 25        │ 0           │ 2          │ 9           │\n",
       "│ 16   │ 1          │ 0          │ 4     │ 256   │ 0.1     │ SGD       │ 30    │ 24        │ 0           │ 2          │ 9           │\n",
       "│ 17   │ 1          │ 0          │ 16    │ 256   │ 0.1     │ SGD       │ 20    │ 17        │ 0           │ 2          │ 9           │\n",
       "│ 18   │ 1          │ 0          │ 16    │ 256   │ 0.1     │ SGD       │ 30    │ 26        │ 0           │ 2          │ 9           │\n",
       "│ 19   │ 1          │ 0          │ 8     │ 128   │ 0.01    │ Rmsprop   │ 20    │ 23        │ 0           │ 2          │ 9           │\n",
       "│ 20   │ 1          │ 0          │ 8     │ 128   │ 0.1     │ SGD       │ 20    │ 15        │ 0           │ 2          │ 9           │\n",
       "│ 21   │ 1          │ 0          │ 2     │ 256   │ 0.1     │ SGD       │ 30    │ 24        │ 0           │ 3          │ 9           │\n",
       "│ 22   │ 1          │ 0          │ 4     │ 128   │ 0.01    │ Rmsprop   │ 10    │ 22        │ 0           │ 3          │ 9           │\n",
       "│ 23   │ 0          │ 0          │ 1     │ 256   │ 0.001   │ Adam      │ 20    │ 23        │ 0           │ 4          │ 9           │\n",
       "│ 24   │ 0          │ 0          │ 2     │ 256   │ 0.001   │ Rmsprop   │ 20    │ 22        │ 0           │ 4          │ 9           │\n",
       "│ 25   │ 0          │ 0          │ 2     │ 128   │ 0.001   │ Rmsprop   │ 30    │ 22        │ 0           │ 4          │ 9           │\n",
       "│ 26   │ 0          │ 0          │ 4     │ 128   │ 0.001   │ Adam      │ 30    │ 19        │ 0           │ 5          │ 9           │\n",
       "│ 27   │ 1          │ 0          │ 2     │ 256   │ 0.001   │ Rmsprop   │ 30    │ 23        │ 0           │ 6          │ 9           │\n",
       "│ 28   │ 0          │ 0          │ 16    │ 128   │ 0.001   │ Adam      │ 30    │ 19        │ 0           │ 6          │ 9           │\n",
       "│ 29   │ 0          │ 0          │ 2     │ 128   │ 0.1     │ SGD       │ 20    │ 24        │ 0           │ 8          │ 9           │\n",
       "│ 30   │ 0          │ 0          │ 2     │ 256   │ 0.1     │ SGD       │ 30    │ 23        │ 0           │ 9          │ 9           │\n",
       "│ 31   │ 1          │ 0          │ 16    │ 128   │ 0.1     │ SGD       │ 10    │ 19        │ 0           │ 9          │ 9           │\n",
       "│ 32   │ 0          │ 0          │ 4     │ 256   │ 0.1     │ SGD       │ 20    │ 20        │ 0           │ 13         │ 9           │\n",
       "│ 33   │ 1          │ 0          │ 4     │ 256   │ 0.1     │ SGD       │ 10    │ 23        │ 0           │ 14         │ 9           │\n",
       "│ 34   │ 1          │ 0          │ 16    │ 256   │ 0.1     │ SGD       │ 10    │ 22        │ 0           │ 14         │ 9           │\n",
       "│ 35   │ 0          │ 0          │ 16    │ 256   │ 0.001   │ Rmsprop   │ 30    │ 17        │ 0           │ 17         │ 9           │\n",
       "│ 36   │ 1          │ 0          │ 8     │ 256   │ 0.001   │ Rmsprop   │ 20    │ 21        │ 0           │ 27         │ 9           │\n",
       "│ 37   │ 1          │ 0          │ 1     │ 256   │ 0.01    │ Adam      │ 10    │ 23        │ 1           │ 0          │ 8           │\n",
       "│ 38   │ 1          │ 0          │ 4     │ 256   │ 0.01    │ Adam      │ 30    │ 22        │ 1           │ 0          │ 8           │\n",
       "│ 39   │ 1          │ 0          │ 16    │ 256   │ 0.01    │ Adam      │ 20    │ 21        │ 1           │ 0          │ 8           │\n",
       "│ 40   │ 1          │ 0          │ 16    │ 256   │ 0.01    │ Adam      │ 30    │ 20        │ 1           │ 0          │ 8           │\n",
       "│ 41   │ 1          │ 0          │ 1     │ 128   │ 0.01    │ Adam      │ 20    │ 18        │ 1           │ 0          │ 8           │\n",
       "│ 42   │ 1          │ 0          │ 2     │ 128   │ 0.01    │ Adam      │ 20    │ 17        │ 1           │ 0          │ 8           │\n",
       "│ 43   │ 1          │ 0          │ 4     │ 128   │ 0.01    │ Adam      │ 20    │ 20        │ 1           │ 0          │ 8           │\n",
       "│ 44   │ 1          │ 0          │ 4     │ 128   │ 0.01    │ Rmsprop   │ 30    │ 21        │ 1           │ 0          │ 8           │\n",
       "│ 45   │ 1          │ 0          │ 2     │ 128   │ 0.1     │ SGD       │ 30    │ 21        │ 1           │ 0          │ 8           │\n",
       "⋮\n",
       "│ 1395 │ 0          │ 1          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1396 │ 0          │ 0          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1397 │ 1          │ 0          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1398 │ 0          │ 1          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1399 │ 1          │ 1          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1400 │ 0          │ 0          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1401 │ 1          │ 0          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1402 │ 0          │ 1          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1403 │ 1          │ 1          │ 4     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1404 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1405 │ 1          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1406 │ 0          │ 1          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1407 │ 1          │ 1          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1408 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1409 │ 1          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1410 │ 0          │ 1          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1411 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1412 │ 1          │ 0          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1413 │ 0          │ 1          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1414 │ 1          │ 1          │ 8     │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1415 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1416 │ 1          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1417 │ 0          │ 1          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1418 │ 1          │ 1          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1419 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1420 │ 1          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1421 │ 0          │ 1          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1422 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1423 │ 1          │ 0          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1424 │ 0          │ 1          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1425 │ 1          │ 1          │ 16    │ 128   │ 1.0     │ Rmsprop   │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1426 │ 0          │ 0          │ 1     │ 128   │ 1.0     │ SGD       │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1427 │ 0          │ 0          │ 1     │ 128   │ 1.0     │ SGD       │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1428 │ 0          │ 0          │ 1     │ 128   │ 1.0     │ SGD       │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1429 │ 0          │ 0          │ 2     │ 128   │ 1.0     │ SGD       │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1430 │ 0          │ 0          │ 2     │ 128   │ 1.0     │ SGD       │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1431 │ 0          │ 0          │ 2     │ 128   │ 1.0     │ SGD       │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1432 │ 0          │ 0          │ 4     │ 128   │ 1.0     │ SGD       │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1433 │ 0          │ 0          │ 4     │ 128   │ 1.0     │ SGD       │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1434 │ 0          │ 0          │ 4     │ 128   │ 1.0     │ SGD       │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1435 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ SGD       │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1436 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ SGD       │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1437 │ 0          │ 0          │ 8     │ 128   │ 1.0     │ SGD       │ 30    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1438 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ SGD       │ 10    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1439 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ SGD       │ 20    │ 0         │ 9           │ 100        │ 0           │\n",
       "│ 1440 │ 0          │ 0          │ 16    │ 128   │ 1.0     │ SGD       │ 30    │ 0         │ 9           │ 100        │ 0           │"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2 |> @orderby_descending(_.UnseenClass) |> @thenby(_.WrongCount) |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 31 entries:\n",
       "  \"4a\" => (L = 2.30187, y = \"6b\", att = (αe = (αμ = K32(256,30)[1.8441857e-5⋯], ασ = K32(256,30)[4.5115175e-5⋯]), αd = nothing))\n",
       "  \"4d\" => (L = 1.86366, y = \"0c\", att = (αe = (αμ = K32(256,30)[1.749927e-5⋯], ασ = K32(256,30)[4.5498175e-5⋯]), αd = nothing))\n",
       "  \"6d\" => (L = 0.929366, y = \"6d\", att = (αe = (αμ = K32(256,30)[1.9662112e-7⋯], ασ = K32(256,30)[4.431309e-7⋯]), αd = nothing))\n",
       "  \"6b\" => (L = 1.87, y = \"8h\", att = (αe = (αμ = K32(256,30)[2.0375037e-7⋯], ασ = K32(256,30)[4.5178157e-7⋯]), αd = nothing))\n",
       "  \"6e\" => (L = 1.18254, y = \"4b\", att = (αe = (αμ = K32(256,30)[1.9590901e-7⋯], ασ = K32(256,30)[4.5182693e-7⋯]), αd = nothing))\n",
       "  \"6a\" => (L = 1.77329, y = \"8f\", att = (αe = (αμ = K32(256,30)[1.902861e-7⋯], ασ = K32(256,30)[4.3968257e-7⋯]), αd = nothing))\n",
       "  \"2h\" => (L = 1.78155, y = \"2d\", att = (αe = (αμ = K32(256,30)[9.932463e-7⋯], ασ = K32(256,30)[7.224869e-7⋯]), αd = nothing))\n",
       "  \"2g\" => (L = 0.947404, y = \"2a\", att = (αe = (αμ = K32(256,30)[1.0270276e-6⋯], ασ = K32(256,30)[7.550452e-7⋯]), αd = nothing))\n",
       "  \"8d\" => (L = 1.59162, y = \"0h\", att = (αe = (αμ = K32(256,30)[4.7031876e-6⋯], ασ = K32(256,30)[1.3284064e-5⋯]), αd = nothing))\n",
       "  \"0e\" => (L = 1.38597, y = \"0c\", att = (αe = (αμ = K32(256,30)[6.2948193e-6⋯], ασ = K32(256,30)[3.4498432e-6⋯]), αd = nothing))\n",
       "  \"0c\" => (L = 1.41038, y = \"0g\", att = (αe = (αμ = K32(256,30)[6.427956e-6⋯], ασ = K32(256,30)[3.4534705e-6⋯]), αd = nothing))\n",
       "  \"4h\" => (L = 2.18324, y = \"2d\", att = (αe = (αμ = K32(256,30)[1.8366909e-5⋯], ασ = K32(256,30)[4.5034496e-5⋯]), αd = nothing))\n",
       "  \"2b\" => (L = 1.63534, y = \"4g\", att = (αe = (αμ = K32(256,30)[1.0183885e-6⋯], ασ = K32(256,30)[7.515324e-7⋯]), αd = nothing))\n",
       "  \"2e\" => (L = 1.15216, y = \"2c\", att = (αe = (αμ = K32(256,30)[1.0118674e-6⋯], ασ = K32(256,30)[7.3971836e-7⋯]), αd = nothing))\n",
       "  \"4b\" => (L = 1.17628, y = \"4a\", att = (αe = (αμ = K32(256,30)[1.8585652e-5⋯], ασ = K32(256,30)[4.5781322e-5⋯]), αd = nothing))\n",
       "  \"4g\" => (L = 1.94238, y = \"2b\", att = (αe = (αμ = K32(256,30)[1.7670733e-5⋯], ασ = K32(256,30)[4.5795965e-5⋯]), αd = nothing))\n",
       "  \"2f\" => (L = 1.50596, y = \"4d\", att = (αe = (αμ = K32(256,30)[1.044122e-6⋯], ασ = K32(256,30)[7.740151e-7⋯]), αd = nothing))\n",
       "  \"8e\" => (L = 1.853, y = \"6b\", att = (αe = (αμ = K32(256,30)[4.708195e-6⋯], ασ = K32(256,30)[1.3341573e-5⋯]), αd = nothing))\n",
       "  \"2a\" => (L = 2.02609, y = \"4f\", att = (αe = (αμ = K32(256,30)[1.0917452e-6⋯], ασ = K32(256,30)[8.713588e-7⋯]), αd = nothing))\n",
       "  \"6f\" => (L = 1.33221, y = \"8g\", att = (αe = (αμ = K32(256,30)[2.1016665e-7⋯], ασ = K32(256,30)[4.7585158e-7⋯]), αd = nothing))\n",
       "  \"8b\" => (L = 1.39326, y = \"8d\", att = (αe = (αμ = K32(256,30)[4.8565366e-6⋯], ασ = K32(256,30)[1.3386443e-5⋯]), αd = nothing))\n",
       "  \"0g\" => (L = 1.19327, y = \"0d\", att = (αe = (αμ = K32(256,30)[6.3231987e-6⋯], ασ = K32(256,30)[3.4586462e-6⋯]), αd = nothing))\n",
       "  \"8a\" => (L = 1.39075, y = \"8g\", att = (αe = (αμ = K32(256,30)[4.8084753e-6⋯], ασ = K32(256,30)[1.3148827e-5⋯]), αd = nothing))\n",
       "  \"6g\" => (L = 1.5658, y = \"6a\", att = (αe = (αμ = K32(256,30)[2.0201352e-7⋯], ασ = K32(256,30)[4.675643e-7⋯]), αd = nothing))\n",
       "  \"6c\" => (L = 1.47414, y = \"8b\", att = (αe = (αμ = K32(256,30)[1.9822416e-7⋯], ασ = K32(256,30)[4.5080253e-7⋯]), αd = nothing))\n",
       "  \"0f\" => (L = 1.55879, y = \"6g\", att = (αe = (αμ = K32(256,30)[6.4019605e-6⋯], ασ = K32(256,30)[3.4699178e-6⋯]), αd = nothing))\n",
       "  \"8f\" => (L = 1.20566, y = \"2f\", att = (αe = (αμ = K32(256,30)[4.8005654e-6⋯], ασ = K32(256,30)[1.3669038e-5⋯]), αd = nothing))\n",
       "  \"0h\" => (L = 1.45457, y = \"0f\", att = (αe = (αμ = K32(256,30)[6.4426144e-6⋯], ασ = K32(256,30)[3.4375469e-6⋯]), αd = nothing))\n",
       "  \"0d\" => (L = 1.56026, y = \"0g\", att = (αe = (αμ = K32(256,30)[6.277979e-6⋯], ασ = K32(256,30)[3.4442626e-6⋯]), αd = nothing))\n",
       "  \"4c\" => (L = 0.895335, y = \"4c\", att = (αe = (αμ = K32(256,30)[1.828638e-5⋯], ασ = K32(256,30)[4.588832e-5⋯]), αd = nothing))\n",
       "  \"8c\" => (L = 2.39331, y = \"4g\", att = (αe = (αμ = K32(256,30)[4.8096917e-6⋯], ασ = K32(256,30)[1.3442486e-5⋯]), αd = nothing))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmodel = get_vae_models(128)[2]\n",
    "train!(cmodel, 𝑿; epoch=60, optim=Adam())\n",
    "sampled = sample(cmodel, vocab, 𝑿; N=100)\n",
    "unseen = [s for s in sampled if s ∈ holdout]\n",
    "wrong  = [s for s in sampled if s ∉ [data;holdout]]\n",
    "result = eval(cmodel, vocab, 𝑿)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{String,1}:\n",
       " \"8g\"\n",
       " \"4e\"\n",
       " \"4f\"\n",
       " \"2d\"\n",
       " \"0b\"\n",
       " \"2c\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(L = 0.92936647f0, y = \"6d\", att = (αe = (αμ = K32(256,30)[1.9662112e-7⋯], ασ = K32(256,30)[4.431309e-7⋯]), αd = nothing))\n",
      "(L = 0.8953346f0, y = \"4c\", att = (αe = (αμ = K32(256,30)[1.828638e-5⋯], ασ = K32(256,30)[4.588832e-5⋯]), αd = nothing))\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in result\n",
    "    if k==v.y\n",
    "        println(v)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Cannot convert String to series data for plotting",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] prepareSeriesData(::String) at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/series.jl:15",
      " [3] convertToAnyVector(::String, ::Dict{Symbol,Any}) at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/series.jl:26",
      " [4] macro expansion at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/series.jl:129 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{Plots.SliceIt}, ::String, ::KnetArray{Float32,2}, ::Nothing) at /kuacc/users/eakyurek13/.julia/packages/RecipesBase/zBoFG/src/RecipesBase.jl:275",
      " [6] _process_userrecipes(::Plots.Plot{Plots.PyPlotBackend}, ::Dict{Symbol,Any}, ::Tuple{String,KnetArray{Float32,2}}) at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/pipeline.jl:83",
      " [7] _plot!(::Plots.Plot{Plots.PyPlotBackend}, ::Dict{Symbol,Any}, ::Tuple{String,KnetArray{Float32,2}}) at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/plot.jl:178",
      " [8] #plot#137(::Base.Iterators.Pairs{Symbol,Any,NTuple{4,Symbol},NamedTuple{(:xticks, :title, :size, :seriestype),Tuple{Tuple{StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}},String},String,Tuple{Int64,Int64},Symbol}}}, ::typeof(RecipesBase.plot), ::String, ::Vararg{Any,N} where N) at /kuacc/users/eakyurek13/.julia/packages/Plots/Iuc9S/src/plot.jl:57",
      " [9] (::getfield(RecipesBase, Symbol(\"#kw##plot\")))(::NamedTuple{(:xticks, :title, :size, :seriestype),Tuple{Tuple{StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}},String},String,Tuple{Int64,Int64},Symbol}}, ::typeof(RecipesBase.plot), ::String, ::KnetArray{Float32,2}) at ./none:0",
      " [10] #bar#384(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol,Symbol},NamedTuple{(:xticks, :title, :size),Tuple{Tuple{StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}},String},String,Tuple{Int64,Int64}}}}, ::typeof(Plots.bar), ::String, ::Vararg{Any,N} where N) at /kuacc/users/eakyurek13/.julia/packages/RecipesBase/zBoFG/src/RecipesBase.jl:369",
      " [11] (::getfield(Plots, Symbol(\"#kw##bar\")))(::NamedTuple{(:xticks, :title, :size),Tuple{Tuple{StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}},String},String,Tuple{Int64,Int64}}}, ::typeof(Plots.bar), ::String, ::Vararg{Any,N} where N) at ./none:0",
      " [12] top-level scope at In[152]:3"
     ]
    }
   ],
   "source": [
    "inp = \"4h\"\n",
    "v = result[inp]\n",
    "StatsPlots.bar(v.y, sum(v.att.αe.αμ, dims=1), xticks=(0.5:1:length(v[2])-0.5, v[2]), title=\"$inp->$(v[1])\", size=(1200,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"4d\"\n",
    "v = d[inp]\n",
    "StatsPlots.bar(1:length(v[4]), v[3], xticks=(1:length(v[2]), v[2]), title=\"$inp->$(v[1])\", size=(1200,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 |> @orderby_descending(_.UnseenClass) |> @thenby(_.WrongCount) |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels = df2 |>  @filter(_.Epoch==20 && _.Optimizer == \"Rmsprop\" && _.lr==0.001) |> DataFrame\n",
    "@df bestmodels groupedbar(:H, :UnseenClass , group = {Enc_Att = :EncoderAtt, Dec_Att  = :DecoderAtt}, xlabel = \"Models\", ylabel = \"# of Unseen Classes\", title = \"# of Unseen Classes vs Epoch on Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels = df2 |>  @filter(_.Epoch==20 && _.Optimizer == \"Rmsprop\" && _.lr==0.001) |> DataFrame\n",
    "@df bestmodels groupedbar(:H, :WrongCount , group = {Enc_Att = :EncoderAtt, Dec_Att  = :DecoderAtt}, xlabel = \"Models\", ylabel = \"# of Unseen Classes\", title = \"# of Unseen Classes vs Epoch on Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 64\n",
    "H = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forw(lmmodel,x; start_tok=length(vocab)) = lmmodel.output(lmmodel.rnn([length(vocab);x]').y)\n",
    "loss(lmmodel,x) = nll(forw(lmmodel,x),[x;0])\n",
    "    \n",
    "function predict(lmmodel,len; start_tok=length(vocab))\n",
    "    ys = zeros(Int,len)\n",
    "    input = start_tok\n",
    "    for i=1:len\n",
    "        yi = lmmodel.output(lmmodel.rnn([input]).y)\n",
    "        input = catsample(softmax(yi)) # put a random sampling here\n",
    "        ys[i] = input\n",
    "    end\n",
    "    return ys\n",
    "end\n",
    "\n",
    "function train!(model, x_onehot; epoch=20, optim=Adam())\n",
    "    setoptim!(model,optim)\n",
    "    for i=1:epoch\n",
    "        lss = 0.0\n",
    "        cnt = 0\n",
    "        x_onehot = shuffle(x_onehot)\n",
    "        for i=1:length(x_onehot)\n",
    "            x  = x_onehot[i]\n",
    "            J = @diff loss(model,  x)\n",
    "            lss += value(J)\n",
    "            cnt += 1\n",
    "            for w in params(J)\n",
    "                KnetLayers.update!(value(w), grad(J,w), w.opt)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function catsample(p)\n",
    "    p = convert(Array,p)\n",
    "    r = rand()\n",
    "    for c = 1:length(p)\n",
    "        r -= p[c]\n",
    "        r < 0 && return c\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmmodel = (rnn=LSTM(input=V,hidden=H,embed=E,dropout=0.5), output=Linear(input=H,output=V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train!(lmmodel,x_onehot; optim=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(lmmodel,x_onehot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled =[vocab[predict(lmmodel,2)] for i=1:100];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = [join(s) for s in sampled if join(s) ∈ holdout]\n",
    "wrong  = [join(s) for s in sampled if join(s) ∉ [data;holdout]]\n",
    "dkl = KLDivergence(data,holdout,sampled)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
