{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "import Plots: px\n",
    "theme(:default)\n",
    "ENV[\"LINES\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"parser.jl\")\n",
    "include(\"models.jl\")\n",
    "download(SIGDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = map(parseDataLine, eachline(\"./data/Sigmorphon/task1/all/spanish-train-high\"));\n",
    "vocab = Vocabulary(data)\n",
    "edata = encode(data,vocab);\n",
    "test  = map(parseDataLine, eachline(\"./data/Sigmorphon/task1/all/spanish-test\"));\n",
    "tdata = encode(test,vocab);\n",
    "dictionary = [parseDataLine(line) for line in  eachline(\"./data/unimorph/spa/spa\") if line != \"\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.chars.toElement;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(unk = 1, mask = 2, eow = 3, bow = 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.specialIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314523-element Array{String,1}:\n",
       " \"ababilladas\"  \n",
       " \"ababillada\"   \n",
       " \"ababillados\"  \n",
       " \"ababillado\"   \n",
       " \"ababillándose\"\n",
       " \"ababillaos\"   \n",
       " \"ababillarse\"  \n",
       " \"ababíllate\"   \n",
       " ⋮              \n",
       " \"zuzase\"       \n",
       " \"zuzasteis\"    \n",
       " \"zuzaste\"      \n",
       " \"zuzas\"        \n",
       " \"zuza\"         \n",
       " \"zuzo\"         \n",
       " \"zuzó\"         "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsfs    = unique(map(x->join(x.surface),data));\n",
    "testsfs     = unique(map(x->join(x.surface),test)); \n",
    "dictsfs     = unique([map(x->join(x.surface),dictionary); trainsfs; testsfs]);\n",
    "unseensfs   = [x for x in dictsfs if x ∉ trainsfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss = 25.152424862670898,)\n",
      "(loss = 20.944303961181642,)\n",
      "(loss = 19.777203521728516,)\n",
      "(loss = 18.948151272583008,)\n",
      "(loss = 18.09249168548584,)\n",
      "(loss = 17.279334880065917,)\n",
      "(loss = 16.511275077819825,)\n",
      "(loss = 15.886029692077637,)\n",
      "(loss = 15.354880126953125,)\n",
      "(loss = 14.888697891235351,)\n",
      "(loss = 14.466316050720215,)\n",
      "(loss = 14.16699754486084,)\n",
      "(loss = 13.86016085357666,)\n",
      "(loss = 13.609251914978028,)\n",
      "(loss = 13.348343374633789,)\n",
      "(loss = 13.141375604248047,)\n",
      "(loss = 12.976138705444336,)\n",
      "(loss = 12.83149554901123,)\n",
      "(loss = 12.677238688659669,)\n",
      "(loss = 12.558918894958497,)\n",
      "(loss = 12.446060032653808,)\n",
      "(loss = 12.367303955078125,)\n",
      "(loss = 12.301560801696777,)\n",
      "(loss = 12.199133605957032,)\n",
      "(loss = 12.177544729614258,)\n",
      "(loss = 12.119846543884277,)\n",
      "(loss = 12.04534634399414,)\n",
      "(loss = 12.017223941040038,)\n",
      "(loss = 11.953271673583984,)\n",
      "(loss = 11.934177980041504,)\n",
      "(loss = 11.89070922241211,)\n",
      "(loss = 11.858240467834472,)\n",
      "(loss = 11.80096760559082,)\n",
      "(loss = 11.745944607543946,)\n",
      "(loss = 11.773284625244141,)\n",
      "(loss = 11.734060075378418,)\n",
      "(loss = 11.714573828125,)\n",
      "(loss = 11.698682055664063,)\n",
      "(loss = 11.645760679626465,)\n",
      "(loss = 11.624648020935059,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(encoder = LSTM{Param{KnetArray{Float32,3}}, Multiply{Param{KnetArray{Float32,2}}}}(input=38,hidden=512,embed=16), Wμ = Multiply{Param{KnetArray{Float32,2}}}(input=512 output=8), Wσ = Dense{ELU}(Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=8), Bias{Param{KnetArray{Float32,1}}}(length=8))), Weaμ = Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=512), Bias{Param{KnetArray{Float32,1}}}(length=512)), Weaσ = Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=512), Bias{Param{KnetArray{Float32,1}}}(length=512)), Wμa = Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=512), Bias{Param{KnetArray{Float32,1}}}(length=512)), Wσa = Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=512), Bias{Param{KnetArray{Float32,1}}}(length=512)), output = Linear(Multiply{Param{KnetArray{Float32,2}}}(input=512 output=38), Bias{Param{KnetArray{Float32,1}}}(length=38)), Wdec = Multiply{Param{KnetArray{Float32,2}}}(input=8 output=512), decoder = LSTM{Param{KnetArray{Float32,3}}, Nothing}(input=24,hidden=512,dropout=0.4), dec_embed = Multiply{Param{KnetArray{Float32,2}}}(input=38 output=16), num = 2, latentSize = 8, hiddenSize = 512)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = EncAttentiveVAE(length(vocab.chars), edata.num; H=512, E=16, Z=8, concatz=true)\n",
    "train_ae!(morph, data, vocab; optim=Adam(lr=0.002), epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(kl_weight = 0.1f0, fbr = 3, loss = 22.94505267944336)\n",
      "(kl_weight = 0.2f0, fbr = 3, loss = 19.93977203979492)\n",
      "(kl_weight = 0.3f0, fbr = 3, loss = 18.93708644104004)\n",
      "(kl_weight = 0.4f0, fbr = 3, loss = 18.027853141784668)\n",
      "(kl_weight = 0.5f0, fbr = 3, loss = 17.18918165283203)\n",
      "(kl_weight = 0.6f0, fbr = 3, loss = 16.43978777770996)\n",
      "(kl_weight = 0.70000005f0, fbr = 3, loss = 15.810721081542969)\n",
      "(kl_weight = 0.8000001f0, fbr = 3, loss = 15.276646681213379)\n",
      "(kl_weight = 0.9000001f0, fbr = 3, loss = 14.851471719360351)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 14.466966752624511)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 14.145613027954102)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 13.885805085754395)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 13.631450276184083)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 13.433302351379394)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 13.20930485534668)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 13.06755604095459)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.92245524597168)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.79308000793457)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.65922205657959)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.615421789550782)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.500514555358887)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.442625541687011)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.388400740051269)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.312806349182129)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.257720942687989)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.217289862060547)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.179188624572754)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.126205487060547)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.090488934326173)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.067911781311036)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.060857098388672)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 12.015937022399902)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.99003524017334)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.934293855285645)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.948347352600099)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.925367292785644)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.883773052978515)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.906943309020996)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.883375367736816)\n",
      "(kl_weight = 1.0f0, fbr = 3, loss = 11.864369906616211)\n"
     ]
    }
   ],
   "source": [
    "morphv =  EncAttentiveVAE(length(vocab.chars), edata.num; H=512, E=16, Z=8, concatz=true)\n",
    "transferto!(morphv.encoder, morph.encoder)\n",
    "transferto!(morphv.Wμ, morph.Wμ)\n",
    "transferto!(morphv.Wσa, morph.Wσa)\n",
    "transferto!(morphv.Wμa, morph.Wμa)\n",
    "transferto!(morphv.Wσ, morph.Wσ)\n",
    "transferto!(morphv.Weaμ, morph.Weaμ)\n",
    "transferto!(morphv.Weaσ, morph.Weaσ)\n",
    "transferto!(morphv.dec_embed,morph.dec_embed)\n",
    "train_vae!(morphv, data, vocab; optim=Adam(lr=0.002), epoch=40, kl_weight=0.0f0, kl_rate = 0.1f0, fb_rate=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(morphv, vocab, edata; N=10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290-element Array{String,1}:\n",
       " \"desairarían\"  \n",
       " \"predichas\"    \n",
       " \"no añejes\"    \n",
       " \"aliaba\"       \n",
       " \"agregaras\"    \n",
       " \"abjurados\"    \n",
       " \"silenciara\"   \n",
       " \"obstruiréis\"  \n",
       " ⋮              \n",
       " \"afrentemos\"   \n",
       " \"enlataremos\"  \n",
       " \"atenazarás\"   \n",
       " \"descuajemos\"  \n",
       " \"despobláremos\"\n",
       " \"mire\"         \n",
       " \"implorabais\"  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(samples[findall([s ∈ trainsfs for s in samples])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4716"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(samples[findall([s ∈ trainsfs for s in samples])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{String,1}:\n",
       " \"nixtamalizare\"\n",
       " \"enrole\"       \n",
       " \"conviviese\"   \n",
       " \"explosionara\" \n",
       " \"historiaba\"   \n",
       " \"reestructura\" \n",
       " \"estragara\"    \n",
       " \"pinchare\"     \n",
       " \"sistematizaba\"\n",
       " \"balbuciera\"   \n",
       " \"puntaren\"     \n",
       " \"refundamos\"   "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(samples[findall([s ∈ testsfs for s in samples])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(samples[findall([s ∈ testsfs for s in samples])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 6509"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(length(samples[findall([s ∈ dictsfs for s in samples])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{String,1}:\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\"\n",
       " \"abarrotare\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinter(morphv, vocab, data; N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, Float32[1.2510026e-22; 2.658151e-23; … ; 5.19158e-23; 1.1128319e-25], K32(8,1)[-4.2638976e-10⋯])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au, sigma, mu = calc_au(morphv,tdata; delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.036793243408203224"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = calc_mi(morphv,tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.040073511622641"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ppl(morphv,tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atts = attentions(morph,edata, vocab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getsingle(sfs,exs,perms, αs,i) \n",
    "    join(vocab.chars[sfs[i]]), map(e->join(vocab.chars[e]),exs[i][perms[i]]), map(x->x[:,perms[i],i],αs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = rand(1:length(atts))\n",
    "s1,e1,α1 =  getsingle(atts[i]...,rand(1:16))\n",
    "ys = 1:512\n",
    "h1 = heatmap(e1, ys, α1.αu; size=(1200,800), xtickfont = font(10, \"Halvetica\"), title= s1 * \", mu\", xrotation = 45, titlefontsize=10, left_margin=100px, bottom_margin=100px, right_margin=100px);\n",
    "h2 = heatmap(e1, ys, α1.ασ ;size=(1200,800), xtickfont = font(10, \"Halvetica\"), title=s1 * \", sigma\", xrotation = 45, titlefontsize=10, left_margin=100px, bottom_margin=100px, right_margin=100px);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(s1);println(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Dos\n",
    "1. Add unrelated surface forms to the examplars too see whether the attention mappings are meaningful\n",
    "2. Comparing with Normal Vae\n",
    "3. Different Sampling Function on LM ($top_k$, temperature)\n",
    "4. Attention in Decoder\n",
    "5. Attention to the hidden state sequence, not just to the final state.\n",
    "6. Metric for testing generation quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nsample_packed_sequence (generic function with 1 method)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"models.jl\")\n",
    "include(\"parser.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph3=nothing; morphv=nothing; morph=nothing; morph2=nothing; KnetLayers.gc();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loss = 24.226039373779297,)\n",
      "(loss = 17.94939325866699,)\n",
      "(loss = 14.63141618347168,)\n",
      "(loss = 11.688678450012207,)\n",
      "(loss = 9.555169277191162,)\n",
      "(loss = 7.757795697784424,)\n",
      "(loss = 6.42142120513916,)\n",
      "(loss = 5.461640008163452,)\n",
      "(loss = 4.630353671264649,)\n",
      "(loss = 3.879816455459595,)\n",
      "(loss = 3.2313405588150026,)\n",
      "(loss = 2.7009236671447754,)\n",
      "(loss = 2.2843154739379883,)\n",
      "(loss = 1.964221185016632,)\n",
      "(loss = 1.8177687578201294,)\n",
      "(loss = 1.5614021615982057,)\n",
      "(loss = 1.3386266157627105,)\n",
      "(loss = 1.3330284670352937,)\n",
      "(loss = 1.1747992154598237,)\n",
      "(loss = 1.0711584807395935,)\n"
     ]
    }
   ],
   "source": [
    "morph2 = VAE(length(vocab.chars); H=512, E=16, Z=16, concatz=true)\n",
    "train_ae!(morph2, data, vocab; optim=Adam(), B=16, epoch=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(vocab.chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(kl_weight = 0.1f0, fbr = 4, loss = 21.441761749267577)\n",
      "(kl_weight = 0.2f0, fbr = 4, loss = 20.253545791625978)\n",
      "(kl_weight = 0.3f0, fbr = 4, loss = 19.015092526245116)\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] _knetptrs(::Any, ::Array{Knet.KnetPtr,1}, ::IdDict{Any,Bool}) at /home/ec2-user/.julia/packages/Knet/icbiq/src/gcnode.jl:126 (repeats 3 times)",
      " [2] knetptrs(::Tuple{KnetArray{Float32,2},KnetArray{Float32,3},KnetArray{Float32,3},KnetArray{UInt8,1},KnetArray{UInt8,1}}) at /home/ec2-user/.julia/packages/Knet/icbiq/src/gcnode.jl:83",
      " [3] knetgcinit(::AutoGrad.Tape) at /home/ec2-user/.julia/packages/Knet/icbiq/src/gcnode.jl:0",
      " [4] knetgcnode(::AutoGrad.Node, ::AutoGrad.Tape) at /home/ec2-user/.julia/packages/Knet/icbiq/src/gcnode.jl:50",
      " [5] #differentiate#3(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(AutoGrad.differentiate), ::Function) at /home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:168",
      " [6] differentiate at /home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:135 [inlined]",
      " [7] #train_vae!#1615(::Int64, ::Adam, ::Int64, ::Nothing, ::Float32, ::Float32, ::Int64, ::typeof(train_vae!), ::NamedTuple{(:encoder, :Wμ, :Wσ, :output, :Wdec, :decoder, :dec_embed, :num, :latentSize, :hiddenSize),Tuple{LSTM{Param{KnetArray{Float32,3}},Multiply{Param{KnetArray{Float32,2}}}},Multiply{Param{KnetArray{Float32,2}}},Dense{ELU},Multiply{Param{KnetArray{Float32,2}}},Multiply{Param{KnetArray{Float32,2}}},LSTM{Param{KnetArray{Float32,3}},Nothing},Multiply{Param{KnetArray{Float32,2}}},Int64,Int64,Int64}}, ::Array{NamedTuple{(:surface, :lemma, :tags),Tuple{Array{Char,1},Array{Char,1},Array{SubString{String},1}}},1}, ::Vocabulary) at /home/ec2-user/compgen/models.jl:210",
      " [8] (::getfield(Main, Symbol(\"#kw##train_vae!\")))(::NamedTuple{(:B, :optim, :epoch, :kl_weight, :kl_rate, :fb_rate),Tuple{Int64,Adam,Int64,Float32,Float32,Int64}}, ::typeof(train_vae!), ::NamedTuple{(:encoder, :Wμ, :Wσ, :output, :Wdec, :decoder, :dec_embed, :num, :latentSize, :hiddenSize),Tuple{LSTM{Param{KnetArray{Float32,3}},Multiply{Param{KnetArray{Float32,2}}}},Multiply{Param{KnetArray{Float32,2}}},Dense{ELU},Multiply{Param{KnetArray{Float32,2}}},Multiply{Param{KnetArray{Float32,2}}},LSTM{Param{KnetArray{Float32,3}},Nothing},Multiply{Param{KnetArray{Float32,2}}},Int64,Int64,Int64}}, ::Array{NamedTuple{(:surface, :lemma, :tags),Tuple{Array{Char,1},Array{Char,1},Array{SubString{String},1}}},1}, ::Vocabulary) at ./none:0",
      " [9] top-level scope at In[210]:6"
     ]
    }
   ],
   "source": [
    "morph3 = VAE(length(vocab.chars); H=512, E=16, Z=16)\n",
    "transferto!(morph3.encoder, morph2.encoder)\n",
    "transferto!(morph3.Wμ, morph2.Wμ)\n",
    "transferto!(morph3.Wσ, morph2.Wσ)\n",
    "transferto!(morph3.dec_embed, morph3.encoder.embedding)\n",
    "train_vae!(morph3, data, vocab; B=16, optim=Adam(lr=0.002), epoch=40, kl_weight=0.0f0, kl_rate = 0.1f0, fb_rate=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(morph3, vocab, edata; N=10000, useprior=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] Type at ./boot.jl:404 [inlined]",
      " [2] findall(::Array{Bool,1}) at ./array.jl:2028",
      " [3] top-level scope at In[212]:1"
     ]
    }
   ],
   "source": [
    "samples[findall([s ∈ trainsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{String,1}:\n",
       " \"okupara\"      \n",
       " \"no enamore\"   \n",
       " \"situarías\"    \n",
       " \"vibrase\"      \n",
       " \"no deleguemos\"\n",
       " \"refundamos\"   "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[findall([s ∈ testsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Force throwing a SIGINT\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] sizeof at ./strings/string.jl:85 [inlined]",
      " [2] ==(::String, ::String) at ./strings/string.jl:104",
      " [3] in(::String, ::Array{String,1}) at ./operators.jl:1056",
      " [4] (::getfield(Main, Symbol(\"##1683#1684\")))(::String) at ./none:0",
      " [5] iterate at ./generator.jl:47 [inlined]",
      " [6] collect_to!(::Array{Bool,1}, ::Base.Generator{Array{String,1},getfield(Main, Symbol(\"##1683#1684\"))}, ::Int64, ::Int64) at ./array.jl:651",
      " [7] collect_to_with_first!(::Array{Bool,1}, ::Bool, ::Base.Generator{Array{String,1},getfield(Main, Symbol(\"##1683#1684\"))}, ::Int64) at ./array.jl:630",
      " [8] collect(::Base.Generator{Array{String,1},getfield(Main, Symbol(\"##1683#1684\"))}) at ./array.jl:611",
      " [9] top-level scope at In[214]:1"
     ]
    }
   ],
   "source": [
    "samples[findall([s ∈ dictsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] Type at ./boot.jl:404 [inlined]",
      " [2] findall(::Array{Bool,1}) at ./array.jl:2028",
      " [3] top-level scope at In[215]:1"
     ]
    }
   ],
   "source": [
    "samples[findall([s ∈ unseensfs for s in samples])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{String,1}:\n",
       " \"contrastemos\"\n",
       " \"contrastemos\"\n",
       " \"contrasteis\" \n",
       " \"contrasteis\" \n",
       " \"contrasteis\" \n",
       " \"contrasteis\" \n",
       " \"sobrecaríais\"\n",
       " \"respararíais\"\n",
       " \"recontaríais\"\n",
       " \"recontaríais\"\n",
       " \"recontaríais\"\n",
       " \"recontaríais\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inters = sampleinter(morph3, vocab, data; N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       "  1\n",
       "  2\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findall([s ∈ dictsfs for s in inters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, Float32[0.394202; 0.30743402; … ; 0.62694967; 0.25517163], K32(16,1)[0.03776209⋯])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au, sigma, mu = calc_au(morph3, tdata; delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1721899108886724"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi =  calc_mi(morph3,tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ppl(morph3, edata; nsample=500, B=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nsample_packed_sequence (generic function with 1 method)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"models.jl\")\n",
    "include(\"parser.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_LM(length(vocab.chars); H=768, E=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnnlm!(model, data, vocab; epoch=40, optim=Adam(), B=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " calc_ppllm(model, tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(model, vocab; N=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[findall([s ∈ trainsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[findall([s ∈ testsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[findall([s ∈ dictsfs for s in samples])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " calc_ppllm(model, edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@eval [mod,] ex\n",
       "\\end{verbatim}\n",
       "Evaluate an expression with values interpolated into it using \\texttt{eval}. If two arguments are provided, the first is the module to evaluate in.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "@eval [mod,] ex\n",
       "```\n",
       "\n",
       "Evaluate an expression with values interpolated into it using `eval`. If two arguments are provided, the first is the module to evaluate in.\n"
      ],
      "text/plain": [
       "\u001b[36m  @eval [mod,] ex\u001b[39m\n",
       "\n",
       "  Evaluate an expression with values interpolated into it using \u001b[36meval\u001b[39m. If two\n",
       "  arguments are provided, the first is the module to evaluate in."
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
