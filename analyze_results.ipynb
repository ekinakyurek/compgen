{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "plt.rc('text', usetex=False)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Loading Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", font_scale=1.5, color_codes=True)\n",
    "# sns.set(, rc={'text.usetex' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(fname):\n",
    "    splits = !grep -hnr 'TEST EVALS\\|VAL EVALS\\|TEST EASY\\|VAL EASY' {fname}\n",
    "    length = !wc -l {fname}\n",
    "    length = int(length[0].split(' ')[0])\n",
    "    starts = []\n",
    "    names  = []\n",
    "    for s in splits:\n",
    "        start,sname = s.split(':')\n",
    "        starts.append(int(start))\n",
    "        names.append(sname)\n",
    "    starts.append(length)\n",
    "    sdict = {}\n",
    "    for i in range(0,len(starts)-1):\n",
    "        sdict[names[i]] = slice(starts[i],starts[i+1])\n",
    "    return sdict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(line):\n",
    "    return line.split(\" \")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_matching_block(lines,start):\n",
    "    index = start\n",
    "    found = False\n",
    "    for l in lines[start:]:\n",
    "        if l.startswith('INPUT:'):\n",
    "            found = True\n",
    "            break\n",
    "        index+=1\n",
    "    if found:\n",
    "        inp   = lines[index]\n",
    "        ref   = get_tokens(lines[index+1])\n",
    "        pred  = get_tokens(lines[index+2])\n",
    "        return (inp,ref,pred), index+3\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(lines):\n",
    "    start=0 \n",
    "    finished = False\n",
    "    preds, tps, fps, fns, f1s= [],[],[],[],[]\n",
    "    while not finished:\n",
    "        data, start = find_next_matching_block(lines,start)\n",
    "        if data is not None:\n",
    "            inp, ref, pred_here = data\n",
    "            tp = (len([p for p in pred_here if p in ref]))\n",
    "            fp = (len([p for p in pred_here if p not in ref]))\n",
    "            fn = (len([p for p in ref if p not in pred_here]))\n",
    "            prec = tp / (tp + fp)\n",
    "            rec = tp / (tp + fn)\n",
    "            if prec == 0 or rec == 0:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2 * prec * rec / (prec + rec)\n",
    "            f1s.append(f1)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "            preds.append(pred_here == ref)\n",
    "        else:\n",
    "            finished = True\n",
    "    tp, fp, fn = np.sum(tps), np.sum(fps), np.sum(fns)\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    if prec == 0 or rec == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * prec * rec / (prec + rec)\n",
    "    return np.mean(preds), np.std(preds),f1,np.std(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_unreduced(lines):\n",
    "    start=0 \n",
    "    finished = False\n",
    "    preds, tps, fps, fns, f1s= [],[],[],[],[]\n",
    "    while not finished:\n",
    "        data, start = find_next_matching_block(lines,start)\n",
    "        if data is not None:\n",
    "            inp, ref, pred_here = data\n",
    "            tp = (len([p for p in pred_here if p in ref]))\n",
    "            fp = (len([p for p in pred_here if p not in ref]))\n",
    "            fn = (len([p for p in ref if p not in pred_here]))\n",
    "            prec = tp / (tp + fp)\n",
    "            rec = tp / (tp + fn)\n",
    "            if prec == 0 or rec == 0:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2 * prec * rec / (prec + rec)\n",
    "            f1s.append(f1)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "            preds.append(pred_here == ref)\n",
    "        else:\n",
    "            finished = True\n",
    "    tp, fp, fn = np.sum(tps), np.sum(fps), np.sum(fns)\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    if prec == 0 or rec == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * prec * rec / (prec + rec)\n",
    "    return np.mean(preds), preds, f1, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/SIGDataSet/spanish/logs/2proto.vae.true.hints.4.seed.0.cond.log\n",
      "split: TEST EVALS\n",
      " (0.14, 0.34698703145794946, 0.7411865864144453, 0.18678766329735408)\n",
      "split: VAL EVALS\n",
      " (0.02, 0.13999999999999999, 0.47993579454253615, 0.19854781800481414)\n",
      "split: TEST EASY\n",
      " (0.61, 0.4877499359302879, 0.8627450980392157, 0.19229000089563794)\n",
      "split: VAL EASY\n",
      " (0.62, 0.48538644398046393, 0.8636763412489007, 0.22038132700600857)\n"
     ]
    }
   ],
   "source": [
    "testfile = \"./checkpoints/SIGDataSet/spanish/logs/2proto.vae.true.hints.4.seed.0.cond.log\"\n",
    "testlines  = open(testfile,'r').readlines()\n",
    "print(testfile)\n",
    "for (s,r) in get_splits(testfile).items():\n",
    "         print(f\"split: {s}\\n\",calculate_scores(testlines[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_scores(df=None,\n",
    "                    langs=(\"spanish\",\"turkish\",\"swahili\"),\n",
    "                    hintss=(4,8,16),\n",
    "                    seeds=(0,1,2,3,4),\n",
    "                    vaes =(\"true\",\"false\"),\n",
    "                    models=(\"baseline\",\"0proto\",\"1proto\",\"2proto\"),\n",
    "                    exppath=\"./checkpoints\",\n",
    "                   ):\n",
    "    for lang in langs:\n",
    "        for hints in hintss:\n",
    "            for seed in seeds:\n",
    "                for vae in vaes:\n",
    "                    for model in  models:\n",
    "                        langpath=os.path.join(exppath,\"SIGDataSet\",lang)\n",
    "                        if model == \"baseline\" or model == \"geca\":\n",
    "                            identifier =\"{}.hints.{}.seed.{}\".format(model,hints,seed)\n",
    "                        else:\n",
    "                            identifier =\"{}.vae.{}.hints.{}.seed.{}\".format(model,vae,hints,seed)\n",
    "                        condfile=os.path.join(langpath,\"logs\",identifier+\".cond.log\") \n",
    "                        if os.path.exists(condfile):\n",
    "                            lines  = open(condfile,'r').readlines()\n",
    "                            if len(lines) < 2142:\n",
    "                                print(\"format broken in \"+condfile)\n",
    "                                continue\n",
    "#                             print(\"processing: \"+condfile)\n",
    "                            for (s,r) in get_splits(condfile).items():#splitinfo.items():\n",
    "                                acc, accstd, f1, f1std = calculate_scores(lines[r])  \n",
    "                                df.loc[len(df.index)] = (lang,hints,seed,vae,model,s,acc,accstd,f1,f1std)\n",
    "                        else:\n",
    "                            print(f\"file doesnot exist: {condfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morph Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Hints</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Vae</th>\n",
       "      <th>Model</th>\n",
       "      <th>Split</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Acc_std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>baseline</td>\n",
       "      <td>TEST EVALS</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.099499</td>\n",
       "      <td>0.595486</td>\n",
       "      <td>0.172985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>baseline</td>\n",
       "      <td>VAL EVALS</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.201385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>baseline</td>\n",
       "      <td>TEST EASY</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.873440</td>\n",
       "      <td>0.191549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>baseline</td>\n",
       "      <td>VAL EASY</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.201838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>0proto</td>\n",
       "      <td>TEST EVALS</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.207692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>swahili</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "      <td>geca</td>\n",
       "      <td>VAL EASY</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.893037</td>\n",
       "      <td>0.161466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>swahili</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "      <td>geca</td>\n",
       "      <td>TEST EVALS</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.746372</td>\n",
       "      <td>0.127119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>swahili</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "      <td>geca</td>\n",
       "      <td>VAL EVALS</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>0.707844</td>\n",
       "      <td>0.228641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>swahili</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "      <td>geca</td>\n",
       "      <td>TEST EASY</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.882096</td>\n",
       "      <td>0.167574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>swahili</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "      <td>geca</td>\n",
       "      <td>VAL EASY</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.893037</td>\n",
       "      <td>0.161466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language Hints Seed    Vae     Model       Split   Acc   Acc_std  \\\n",
       "0     spanish     4    0   true  baseline  TEST EVALS  0.01  0.099499   \n",
       "1     spanish     4    0   true  baseline   VAL EVALS  0.03  0.170587   \n",
       "2     spanish     4    0   true  baseline   TEST EASY  0.64  0.480000   \n",
       "3     spanish     4    0   true  baseline    VAL EASY  0.61  0.487750   \n",
       "4     spanish     4    0   true    0proto  TEST EVALS  0.20  0.400000   \n",
       "...       ...   ...  ...    ...       ...         ...   ...       ...   \n",
       "1795  swahili    16    4   true      geca    VAL EASY  0.57  0.495076   \n",
       "1796  swahili    16    4  false      geca  TEST EVALS  0.04  0.195959   \n",
       "1797  swahili    16    4  false      geca   VAL EVALS  0.12  0.324962   \n",
       "1798  swahili    16    4  false      geca   TEST EASY  0.51  0.499900   \n",
       "1799  swahili    16    4  false      geca    VAL EASY  0.57  0.495076   \n",
       "\n",
       "            F1    F1_std  \n",
       "0     0.595486  0.172985  \n",
       "1     0.465753  0.201385  \n",
       "2     0.873440  0.191549  \n",
       "3     0.866667  0.201838  \n",
       "4     0.719523  0.207692  \n",
       "...        ...       ...  \n",
       "1795  0.893037  0.161466  \n",
       "1796  0.746372  0.127119  \n",
       "1797  0.707844  0.228641  \n",
       "1798  0.882096  0.167574  \n",
       "1799  0.893037  0.161466  \n",
       "\n",
       "[1800 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=('Language', 'Hints', 'Seed', 'Vae','Model','Split','Acc','Acc_std','F1','F1_std',))\n",
    "get_lang_scores(df=df,exppath=\"./checkpoints\")\n",
    "get_lang_scores(df=df,exppath=\"./checkpoints_gecaexp\",\n",
    "                models=(\"geca\",))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #options\n",
    "# splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "# splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "# score = \"F1\"\n",
    "# cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"false\"\n",
    "# hints = 8\n",
    "def get_morph_results_graph(df):\n",
    "\n",
    "    #filter based on options\n",
    "    df_filtered = df.replace(splits_s, splits_s_alt).loc[(df['Split'].isin(splits_s)) & (df['Vae'] == vae)  & (df[\"Hints\"]==hints), cols]\n",
    "    df_filtered.head()\n",
    "    print(len(df_filtered))\n",
    "\n",
    "    #aggregate to get the mean\n",
    "    agg = df_filtered.groupby(by=[\"Model\",\"Split\",\"Seed\"]).agg(\"mean\"). \\\n",
    "          reset_index()\n",
    "    agg[\"Language\"] = \"Average\"+score\n",
    "    agg = agg[df_filtered.columns]\n",
    "    print(len(agg))\n",
    "\n",
    "    #new df with mean\n",
    "    df_filtered_avg = df_filtered.append(agg, ignore_index=True)\n",
    "    return(df_filtered_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style({'font.family':'serif', 'font.serif':'Times New Roman'})\n",
    "# sns.set_style({'font.family': 'Times New Roman'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hints=4, NOVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-629254d89898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# vae = \"false\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# hints = 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_filtered_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_morph_results_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_filtered_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Split'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Set'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m palette = {\"baseline\":\"grey\",\n",
      "\u001b[0;32m<ipython-input-11-4d3481edbf25>\u001b[0m in \u001b[0;36mget_morph_results_graph\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#filter based on options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits_s_alt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vae'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hints\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mhints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "#options\n",
    "splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "score = \"F1\"\n",
    "cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"false\"\n",
    "# hints = 4\n",
    "df_filtered_avg = get_morph_results_graph(df)\n",
    "df_filtered_avg.rename(columns={'Split':'Set'}, inplace=True)\n",
    "palette = {\"baseline\":\"grey\",\n",
    "          \"0proto\":\"lightsalmon\",\n",
    "          \"1proto\":\"salmon\",\n",
    "          \"2proto\":\"coral\",\n",
    "          \"geca\":\"cornflowerblue\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morph_graph(df_filtered_avg, hints=4, vae=\"false\"):\n",
    "    g = sns.catplot(x=\"Set\",\n",
    "               y=score,\n",
    "               col=\"Language\",\n",
    "               hue=\"Model\",\n",
    "               col_order=[\"Average\"+score, \"spanish\",\"turkish\",\"swahili\"],\n",
    "               kind=\"bar\",\n",
    "               data=df_filtered_avg,\n",
    "               hue_order=[\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\"],\n",
    "               ci='sd',\n",
    "               palette=palette#sns.color_palette(\"RdBu\", n_colors=5)\n",
    "               )\n",
    "\n",
    "    #fix labels and save\n",
    "    axes = g.axes.flatten()\n",
    "    axes[0].set_title(\"Average\")\n",
    "    axes[0].set_ylim(0.25,)\n",
    "    axes[1].set_title(\"Spanish\")\n",
    "    axes[2].set_title(\"Turkish\")\n",
    "    axes[3].set_title(\"Swahili\")\n",
    "    g.set_xticklabels(rotation=15)\n",
    "    return(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #options\n",
    "# splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "# splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "# score = \"F1\"\n",
    "# cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"false\"\n",
    "# hints = 4\n",
    "# df_filtered_avg = get_morph_results_graph(df)\n",
    "\n",
    "# df_filtered_avg = df_filtered_avg.rename(columns={'Split':'Set'})\n",
    "\n",
    "g = get_morph_graph(df_filtered_avg, hints=4, vae=\"false\")\n",
    "g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hints=4, VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_morph_graph(df_filtered_avg, hints=4, vae=\"true\")\n",
    "g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n",
    "\n",
    "# options\n",
    "# splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "# splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "# score = \"F1\"\n",
    "# cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"true\"\n",
    "# hints = 4\n",
    "# df_filtered_avg = get_morph_results_graph(df)\n",
    "\n",
    "# df_filtered_avg = df_filtered_avg.rename(columns={'Split':'Set'})\n",
    "\n",
    "# palette = {\"baseline\":\"grey\",\n",
    "#           \"0proto\":\"lightsalmon\",\n",
    "#           \"1proto\":\"salmon\",\n",
    "#           \"2proto\":\"coral\",\n",
    "#           \"geca\":\"cornflowerblue\"}\n",
    "\n",
    "# g = sns.catplot(x=\"Set\",\n",
    "#                y=score,\n",
    "#                col=\"Language\",\n",
    "#                hue=\"Model\",\n",
    "#                col_order=[\"Average\"+score, \"spanish\",\"turkish\",\"swahili\"],\n",
    "#                kind=\"bar\",\n",
    "#                data=df_filtered_avg,\n",
    "#                hue_order=[\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\"],\n",
    "#                ci='sd',\n",
    "#                palette=palette#sns.color_palette(\"RdBu\", n_colors=5)\n",
    "#                )\n",
    "\n",
    "# #fix labels and save\n",
    "# axes = g.axes.flatten()\n",
    "# axes[0].set_title(\"Average\")\n",
    "# axes[0].set_ylim(0.25,)\n",
    "# axes[1].set_title(\"Spanish\")\n",
    "# axes[2].set_title(\"Turkish\")\n",
    "# axes[3].set_title(\"Swahili\")\n",
    "# g.set_xticklabels(rotation=15)\n",
    "# g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hints=8, NOVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = get_morph_graph(df_filtered_avg, hints=8, vae=\"false\")\n",
    "g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n",
    "#options\n",
    "# splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "# splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "# score = \"F1\"\n",
    "# cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"false\"\n",
    "# hints = 8\n",
    "# df_filtered_avg = get_morph_results_graph(df)\n",
    "\n",
    "# df_filtered_avg = df_filtered_avg.rename(columns={'Split':'Set'})\n",
    "\n",
    "# palette = {\"baseline\":\"grey\",\n",
    "#           \"0proto\":\"lightsalmon\",\n",
    "#           \"1proto\":\"salmon\",\n",
    "#           \"2proto\":\"coral\",\n",
    "#           \"geca\":\"cornflowerblue\"}\n",
    "\n",
    "# g = sns.catplot(x=\"Set\",\n",
    "#                y=score,\n",
    "#                col=\"Language\",\n",
    "#                hue=\"Model\",\n",
    "#                col_order=[\"Average\"+score, \"spanish\",\"turkish\",\"swahili\"],\n",
    "#                kind=\"bar\",\n",
    "#                data=df_filtered_avg,\n",
    "#                hue_order=[\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\"],\n",
    "#                ci='sd',\n",
    "#                palette=palette#sns.color_palette(\"RdBu\", n_colors=5)\n",
    "#                )\n",
    "\n",
    "# #fix labels and save\n",
    "# axes = g.axes.flatten()\n",
    "# axes[0].set_title(\"Average\")\n",
    "# axes[0].set_ylim(0.25,)\n",
    "# axes[1].set_title(\"Spanish\")\n",
    "# axes[2].set_title(\"Turkish\")\n",
    "# axes[3].set_title(\"Swahili\")\n",
    "# g.set_xticklabels(rotation=15)\n",
    "# g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n",
    "\n",
    "# g = sns.relplot(x=\"Model\", y=score, #units=\"Seed\", \n",
    "#                 #estimator=None, \n",
    "#                 ci=\"sd\",\n",
    "#                 hue=\"Split\", style=\"Split\", col_order=[\"Average\"+score, \"spanish\",\"turkish\",\"swahili\"],\n",
    "#                 col=\"Language\", kind=\"line\", markers=True, data=df_filtered_avg, sort=True, err_style=\"bars\").\\\n",
    "#             map(sns.lineplot, \"Model\", \"F1\", order=[3,0,1,2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hints=8, VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_morph_graph(df_filtered_avg, hints=8, vae=\"true\")\n",
    "g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n",
    "#options\n",
    "# splits_s = [\"TEST EVALS\", \"TEST EASY\", \"VAL EVALS\"]\n",
    "# splits_s_alt = [\"Future Tense\", \"Present Tense\", \"Past Tense\"]\n",
    "# score = \"F1\"\n",
    "# cols = [\"Language\", \"Seed\", \"Model\", \"Split\", score]\n",
    "# vae = \"true\"\n",
    "# hints = 8\n",
    "# df_filtered_avg = get_morph_results_graph(df)\n",
    "\n",
    "# df_filtered_avg = df_filtered_avg.rename(columns={'Split':'Set'})\n",
    "\n",
    "# palette = {\"baseline\":\"grey\",\n",
    "#           \"0proto\":\"lightsalmon\",\n",
    "#           \"1proto\":\"salmon\",\n",
    "#           \"2proto\":\"coral\",\n",
    "#           \"geca\":\"cornflowerblue\"}\n",
    "\n",
    "# g = sns.catplot(x=\"Set\",\n",
    "#                y=score,\n",
    "#                col=\"Language\",\n",
    "#                hue=\"Model\",\n",
    "#                col_order=[\"Average\"+score, \"spanish\",\"turkish\",\"swahili\"],\n",
    "#                kind=\"bar\",\n",
    "#                data=df_filtered_avg,\n",
    "#                hue_order=[\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\"],\n",
    "#                ci='sd',\n",
    "#                palette=palette#sns.color_palette(\"RdBu\", n_colors=5)\n",
    "#                )\n",
    "\n",
    "# #fix labels and save\n",
    "# axes = g.axes.flatten()\n",
    "# axes[0].set_title(\"Average\")\n",
    "# axes[0].set_ylim(0.25,)\n",
    "# axes[1].set_title(\"Spanish\")\n",
    "# axes[2].set_title(\"Turkish\")\n",
    "# axes[3].set_title(\"Swahili\")\n",
    "# g.set_xticklabels(rotation=15)\n",
    "# g.savefig(\"morph_results_hints_{}_vae_{}_{}.pdf\".format(hints,vae,score), dpi=300, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(x):\n",
    "    return(str(round(np.mean(x),2))+\" (${+-}\"+str(round(np.std(x),2))+\"$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_morph_results_table(df, hints=4, vae=\"false\"):\n",
    "#     hints=4\n",
    "#     vae=\"false\"\n",
    "#     splits_s = [\"TEST EVALS\", \"VAL EVALS\", \"TEST EASY\"]\n",
    "#     splits_s_alt = [\"Future Tense\", \"Past Tense\", \"Present Tense\"]\n",
    "#     score_s = [\"Acc\", \"F1\"]\n",
    "#     cols_s = [\"Language\", \"Seed\", \"Model\", \"Split\"] + score_s\n",
    "\n",
    "#     df_filtered_s = df.replace(splits_s, splits_s_alt).\\\n",
    "#                     loc[(df['Split'].isin(splits_s)) & (df['Vae'] == vae) & (df['Hints'] == hints), cols_s].\\\n",
    "#                     reset_index().\\\n",
    "#                     drop(columns=['index'])\n",
    "\n",
    "#     print(\"Len: \", len(df_filtered_s))\n",
    "#     df_mean_std = df_filtered_s.groupby(by=[\"Model\",\"Split\", \"Language\"]).\\\n",
    "#                     agg({\"Acc\":[\"mean\",\"std\"], \"F1\":[\"mean\",\"std\"]}).\\\n",
    "#                     reset_index(\"Split\").pivot(columns=\"Split\")\n",
    "#     df_mean_std.columns = df_mean_std.columns.swaplevel(1,0)\n",
    "#     return(df_mean_std.iloc[:,[0,3,2,5,1,4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mean(x):\n",
    "    return(str(round(np.mean(x),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_morph_results_table_alt_std(df, hints=4, vae=\"false\", markdown=False):\n",
    "    splits_s = [\"TEST EVALS\", \"VAL EVALS\", \"TEST EASY\"]\n",
    "    splits_s_alt = [\"Future Tense\", \"Past Tense\", \"Present Tense\"]\n",
    "    score_s = [\"Acc\", \"F1\"]\n",
    "    cols_s = [\"Language\", \"Seed\", \"Model\", \"Split\"] + score_s\n",
    "\n",
    "    df_filtered_s = df.replace(splits_s, splits_s_alt).\\\n",
    "                    loc[(df['Split'].isin(splits_s)) & (df['Vae'] == vae) & (df['Hints'] == hints), cols_s].\\\n",
    "                    reset_index().\\\n",
    "                    drop(columns=['index'])\n",
    "\n",
    "    func = my_mean if markdown else mean_std\n",
    "    print(\"Len: \", len(df_filtered_s))\n",
    "    df_mean_std = df_filtered_s.groupby(by=[\"Model\",\"Split\", \"Seed\"]).\\\n",
    "                    agg({\"Acc\":\"mean\", \"F1\":\"mean\"}).\\\n",
    "                    reset_index().\\\n",
    "                    groupby(by=[\"Model\",\"Split\"]).\\\n",
    "                    agg({'Acc':func, 'F1':func}).\\\n",
    "                    reset_index(\"Split\").pivot(columns=\"Split\")\n",
    "\n",
    "    df_mean_std.columns = df_mean_std.columns.swaplevel(1,0)\n",
    "    return(df_mean_std.iloc[[3,4,0,1,2,],[0,3,1,4,2,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hints=4, NOVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = get_morph_results_table_alt_std(df)\n",
    "display(df_mean_std)\n",
    "print(df_mean_std.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = get_morph_results_table_alt_std(df, hints=4, vae=\"true\")\n",
    "display(df_mean_std)\n",
    "print(df_mean_std.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = get_morph_results_table_alt_std(df, hints=8, vae=\"false\")\n",
    "display(df_mean_std)\n",
    "print(df_mean_std.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = get_morph_results_table_alt_std(df, hints=8, vae=\"true\")\n",
    "display(df_mean_std)\n",
    "print(df_mean_std.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = get_morph_results_table_alt_std(df, hints=4, vae=\"false\", markdown=True)\n",
    "display(df_mean_std)\n",
    "print(df_mean_std.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCAN Results Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_scores(df=None,\n",
    "                    tasks=(\"jump\",\"around_right\"),\n",
    "                    seeds=(0,1,2,3,4),\n",
    "                    vaes =(\"true\",\"false\"),\n",
    "                    models=(\"0proto\",\"1proto\",\"2proto\"),\n",
    "                    exppath=\"./checkpoints\",\n",
    "                   ):\n",
    "    for task in tasks:\n",
    "            for seed in seeds:\n",
    "                for vae in vaes:\n",
    "                    for model in  models:\n",
    "                        taskpath=os.path.join(exppath,\"SCANDataSet\")\n",
    "                        identifier =\"{}.vae.{}.{}.seed.{}\".format(model,vae,task,seed)\n",
    "                        condfile=os.path.join(taskpath,\"logs\",identifier+\".cond.log\") \n",
    "                        if os.path.exists(condfile):\n",
    "                            lines  = open(condfile,'r').readlines()\n",
    "                            print(\"processing: \"+condfile)\n",
    "                            for (s,r) in get_splits(condfile).items():\n",
    "                                acc, accstd, f1, f1std = calculate_scores(lines[r])  \n",
    "                                df.loc[len(df.index)] = (task,s,seed,vae,model,acc,accstd,f1,f1std)\n",
    "                        else:\n",
    "                            print(f\"file doesnot exist: {condfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create SCAN table\n",
    "dfscan = pd.DataFrame(columns=(\"Task\",'Split', 'Seed', 'Vae','Model','Acc','Acc_std','F1','F1_std',))\n",
    "get_scan_scores(df=dfscan)\n",
    "dfscan_other = pd.DataFrame(columns=(\"Task\",'Split', 'Seed', 'Vae','Model','Acc','Acc_std','F1','F1_std',))\n",
    "get_scan_scores(df=dfscan_other,\n",
    "                models=(\"2proto\",),\n",
    "                tasks=(\"jump\",),\n",
    "                exppath=\"./checkpoints_dgx_scan/\",\n",
    "               )\n",
    "# results with seed 5-9\n",
    "dfscan_other['Seed'] = dfscan_other['Seed'] + 5\n",
    "dfscan_all=dfscan.append(dfscan_other, ignore_index=True)\n",
    "dfscan_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfscan_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_results_table(dfscan_all, markdown=False):\n",
    "    splits_s = [\"TEST EVALS\"]\n",
    "    score_s = \"Acc\"\n",
    "    cols_s = [\"Task\", \"Seed\", \"Model\", \"Split\", score_s]\n",
    "    vae_s = \"false\"\n",
    "    \n",
    "    df_filtered_s = dfscan_all.loc[(dfscan_all['Split'].isin(splits_s)) & (dfscan_all['Vae'] == vae_s), cols_s].\\\n",
    "                    reset_index().\\\n",
    "                    drop(columns=['index', 'Split'])\n",
    "                    \n",
    "    df_filtered_s.head()\n",
    "    print(\"Len: \", len(df_filtered_s))\n",
    "    \n",
    "    # add geca and baseline scores\n",
    "    geca_baseline_s = pd.read_csv(\"stats/scan-geca-baseline.csv\", header=None)\n",
    "    print(\"Total of {} GECA and baseline records.\".format(len(geca_baseline_s)))\n",
    "    \n",
    "    # append\n",
    "    for index,row in geca_baseline_s.iterrows():\n",
    "    \n",
    "        task = row[0]\n",
    "        seed = row[1]\n",
    "        model = row[2]\n",
    "        val = float(row[3])\n",
    "\n",
    "        df_filtered_s.loc[len(df_filtered_s)] = [task, seed, model, val]\n",
    "    \n",
    "    func = my_mean if markdown else mean_std\n",
    "    dfscan_mean_std = df_filtered_s.groupby(by=[\"Model\",\"Task\"]).\\\n",
    "                    agg({\"Acc\":func}).\\\n",
    "                    reset_index(\"Task\").\\\n",
    "                    pivot(columns=\"Task\").\\\n",
    "                    rename(columns={\"around_right\":\"AROUND RIGHT\", \"jump\":\"JUMP\"})\n",
    "\n",
    "    return(dfscan_mean_std.iloc[:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscan_mean_std = get_scan_results_table(dfscan_all)\n",
    "display(dfscan_mean_std)\n",
    "print(dfscan_mean_std.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfscan_mean_std = get_scan_results_table(dfscan_all, markdown=True)\n",
    "print(dfscan_mean_std.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_scores_unreduced(df=None,\n",
    "                    langs=(\"spanish\",\"turkish\",\"swahili\"),\n",
    "                    hintss=(4,8,16),\n",
    "                    seeds=(0,1,2,3,4),\n",
    "                    vaes =(\"true\",\"false\"),\n",
    "                    models=(\"baseline\",\"0proto\",\"1proto\",\"2proto\"),\n",
    "                    exppath=\"./checkpoints\",\n",
    "                   ):\n",
    "    for lang in langs:\n",
    "        for hints in hintss:\n",
    "            for seed in seeds:\n",
    "                for vae in vaes:\n",
    "                    for model in  models:\n",
    "                        langpath=os.path.join(exppath,\"SIGDataSet\",lang)\n",
    "                        if model == \"baseline\" or model == \"geca\":\n",
    "                            identifier =\"{}.hints.{}.seed.{}\".format(model,hints,seed)\n",
    "                        else:\n",
    "                            identifier =\"{}.vae.{}.hints.{}.seed.{}\".format(model,vae,hints,seed)\n",
    "                        condfile=os.path.join(langpath,\"logs\",identifier+\".cond.log\") \n",
    "                        if os.path.exists(condfile):\n",
    "                            lines  = open(condfile,'r').readlines()\n",
    "                            if len(lines) < 2142:\n",
    "                                print(\"format broken in \"+condfile)\n",
    "                                continue\n",
    "#                             print(\"processing: \"+condfile)\n",
    "                            for (s,r) in get_splits(condfile).items():#splitinfo.items():\n",
    "                                acc, accstd, f1, f1std = calculate_scores_unreduced(lines[r])  \n",
    "                                df.loc[len(df.index)] = (lang,hints,seed,vae,model,s,acc,accstd,f1,f1std)\n",
    "                        else:\n",
    "                            print(f\"file doesnot exist: {condfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunreduced = pd.DataFrame(columns=('Language', 'Hints', 'Seed', 'Vae','Model','Split','Acc','Acc_std','F1','F1_std',))\n",
    "get_lang_scores_unreduced(df=dfunreduced,exppath=\"./checkpoints\")\n",
    "get_lang_scores_unreduced(df=dfunreduced,exppath=\"./checkpoints_gecaexp\",\n",
    "                models=(\"geca\",))\n",
    "dfunreduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunreduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "models=(\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\")\n",
    "langs = (\"spanish\", \"turkish\", \"swahili\")\n",
    "hints=4\n",
    "vae=\"false\"\n",
    "split=\"TEST EVALS\"\n",
    "cols = [\"Language\", \"Seed\", \"Model\", \"Acc_std\", \"F1_std\"]\n",
    "conds = (dfunreduced[\"Hints\"]==hints) & (dfunreduced['Vae']==vae) & (dfunreduced[\"Split\"]==split)\n",
    "dfunreduced_filtered = dfunreduced.loc[conds, cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunreduced_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    d[m] = {}\n",
    "    for t in [\"Acc_std\", \"F1_std\"]:\n",
    "        d[m][t] = []\n",
    "        for l in langs:\n",
    "            for s in range(5):\n",
    "                cond1 = (dfunreduced_filtered[\"Model\"]==m) & (dfunreduced_filtered[\"Language\"]==l)\n",
    "                cond2 = (dfunreduced_filtered[\"Seed\"]==s)\n",
    "#                 pdb.set_trace()\n",
    "                if t == \"Acc_std\":\n",
    "                    d[m][t].extend([int(el) for el in dfunreduced_filtered.loc[cond1 & cond2, t].tolist()[0]])\n",
    "                else:\n",
    "                    d[m][t].extend(dfunreduced_filtered.loc[cond1 & cond2, t].tolist()[0])\n",
    "#         d[m][t].update({t:ls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(d[\"baseline\"][\"Acc_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d[\"baseline\"][\"Acc_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d[\"0proto\"][\"Acc_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_avg = {}\n",
    "for m in models:\n",
    "    d_avg[m] = {}\n",
    "    for t in [\"Acc_std\", \"F1_std\"]:\n",
    "#         d_avg[m][t] = {}\n",
    "        d_avg[m][t] = np.mean(d[m][t])\n",
    "#         d_avg[m][t][\"std\"] = np.std(d[m][t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def t_test(model1, model2, t):\n",
    "    return(stats.ttest_rel(d[model1][t],d[model2][t]).pvalue)\n",
    "\n",
    "def get_pvals(t):\n",
    "    sign = {}\n",
    "    for m1 in models:\n",
    "        sign[m1] = {}\n",
    "        for m2 in models:\n",
    "            sign[m1][m2] = t_test(m1,m2,t)\n",
    "    return(pd.DataFrame(sign))\n",
    "print(\"acc\")       \n",
    "display(get_pvals(\"Acc_std\"))\n",
    "print(\"f1\")\n",
    "display(get_pvals(\"F1_std\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1pvalsfut = get_pvals(\"F1_std\")\n",
    "print(f1pvalsfut.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "models=(\"baseline\",\"geca\",\"0proto\",\"1proto\",\"2proto\")\n",
    "langs = (\"spanish\", \"turkish\", \"swahili\")\n",
    "hints=4\n",
    "vae=\"false\"\n",
    "split=\"VAL EVALS\"\n",
    "cols = [\"Language\", \"Seed\", \"Model\", \"Acc_std\", \"F1_std\"]\n",
    "conds = (dfunreduced[\"Hints\"]==hints) & (dfunreduced['Vae']==vae) & (dfunreduced[\"Split\"]==split)\n",
    "dfunreduced_filtered = dfunreduced.loc[conds, cols]\n",
    "\n",
    "for m in models:\n",
    "    d[m] = {}\n",
    "    for t in [\"Acc_std\", \"F1_std\"]:\n",
    "        d[m][t] = []\n",
    "        for l in langs:\n",
    "            for s in range(5):\n",
    "                cond1 = (dfunreduced_filtered[\"Model\"]==m) & (dfunreduced_filtered[\"Language\"]==l)\n",
    "                cond2 = (dfunreduced_filtered[\"Seed\"]==s)\n",
    "#                 pdb.set_trace()\n",
    "                if t == \"Acc_std\":\n",
    "                    d[m][t].extend([int(el) for el in dfunreduced_filtered.loc[cond1 & cond2, t].tolist()[0]])\n",
    "                else:\n",
    "                    d[m][t].extend(dfunreduced_filtered.loc[cond1 & cond2, t].tolist()[0])\n",
    "                    \n",
    "                    \n",
    "d_avg = {}\n",
    "for m in models:\n",
    "    d_avg[m] = {}\n",
    "    for t in [\"Acc_std\", \"F1_std\"]:\n",
    "#         d_avg[m][t] = {}\n",
    "        d_avg[m][t] = np.mean(d[m][t])\n",
    "#         d_avg[m][t][\"std\"] = np.std(d[m][t])\n",
    "\n",
    "f1pvalspst = get_pvals(\"F1_std\")\n",
    "print(f1pvalspst.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_scores_unreduced(df=None,\n",
    "                    tasks=(\"jump\",\"around_right\"),\n",
    "                    seeds=(0,1,2,3,4),\n",
    "                    vaes =(\"true\",\"false\"),\n",
    "                    models=(\"0proto\",\"1proto\",\"2proto\"),\n",
    "                    exppath=\"./checkpoints\",\n",
    "                   ):\n",
    "    for task in tasks:\n",
    "            for seed in seeds:\n",
    "                for vae in vaes:\n",
    "                    for model in  models:\n",
    "                        taskpath=os.path.join(exppath,\"SCANDataSet\")\n",
    "                        identifier =\"{}.vae.{}.{}.seed.{}\".format(model,vae,task,seed)\n",
    "                        condfile=os.path.join(taskpath,\"logs\",identifier+\".cond.log\") \n",
    "                        if os.path.exists(condfile):\n",
    "                            lines  = open(condfile,'r').readlines()\n",
    "                            print(\"processing: \"+condfile)\n",
    "                            for (s,r) in get_splits(condfile).items():\n",
    "                                acc, accstd, f1, f1std = calculate_scores_unreduced(lines[r])  \n",
    "                                df.loc[len(df.index)] = (task,s,seed,vae,model,acc,accstd,f1,f1std)\n",
    "                        else:\n",
    "                            print(f\"file doesnot exist: {condfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscan_ablations = pd.DataFrame(columns=(\"Task\",'Split', 'Seed', 'Vae','Model','Acc','Acc_std','F1','F1_std',))\n",
    "get_scan_scores(df=dfscan_ablations,\n",
    "                models=(\"ID.1proto\",\"nocopy.1proto\", \"nocopy.2proto\"),\n",
    "                exppath=\"./checkpoints_ablations/\",\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfscan_ablations[(dfscan_ablations[\"Split\"]==\"TEST EVALS\") & (dfscan_ablations[\"Task\"]==\"around_right\")]"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
